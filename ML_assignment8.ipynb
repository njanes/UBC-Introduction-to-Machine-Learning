{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Machine Learning  \n",
    "\n",
    "## Assignment 8: Linear Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can't learn technical subjects without hands-on practice. The assignments are an important part of the course. To submit this assignment you will need to make sure that you save your Jupyter notebook. \n",
    "\n",
    "Below are the links of 2 videos that explain:\n",
    "\n",
    "1. [How to save your Jupyter notebook](https://youtu.be/0aoLgBoAUSA) and,       \n",
    "2. [How to answer a question in a Jupyter notebook assignment](https://youtu.be/7j0WKhI3W4s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment Learning Goals:\n",
    "\n",
    "By the end of the module, students are expected to:\n",
    "\n",
    "- Explain the general intuition behind linear models.\n",
    "- Explain the `fit` and `predict` paradigm of linear models.\n",
    "- Use `scikit-learn`'s `LogisticRegression` classifier.\n",
    "    - Use `fit`, `predict` and `predict_proba`.   \n",
    "    - Use `coef_` to interpret the model weights.\n",
    "- Explain the advantages and limitations of linear classifiers. \n",
    "- Apply scikit-learn regression model (e.g., Ridge) to regression problems.\n",
    "- Relate the Ridge hyperparameter `alpha` to the `LogisticRegression` hyperparameter `C`.\n",
    "\n",
    "\n",
    "This assignment covers [Module 8](https://ml-learn.mds.ubc.ca/en/module8) of the online course. You should complete this module before attempting this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any place you see `...`, you must fill in the function, variable, or data to complete the code. Substitute the `None` with your completed code and answers then proceed to run the cell!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that some of the questions in this assignment will have hidden tests. This means that no feedback will be given as to the correctness of your solution. It will be left up to you to decide if your answer is sufficiently correct. These questions are worth 2 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataTransformerRegistry.enable('default')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import libraries needed for this lab\n",
    "from hashlib import sha1\n",
    "\n",
    "import altair as alt\n",
    "import graphviz\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from sklearn import tree\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import make_column_transformer \n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.preprocessing import (\n",
    "    FunctionTransformer,\n",
    "    Normalizer,\n",
    "    OneHotEncoder,\n",
    "    StandardScaler,\n",
    "    normalize,\n",
    "    scale)\n",
    "from sklearn.metrics import plot_confusion_matrix, classification_report\n",
    "from sklearn.svm import SVC, SVR\n",
    "\n",
    "from scipy.stats import lognorm, loguniform, randint\n",
    "\n",
    "import test_assignment8 as t\n",
    "#alt.renderers.enable('mimetype')\n",
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Sentiment analysis on the IMDB dataset \n",
    "\n",
    "<img src=\"https://ia.media-imdb.com/images/M/MV5BMTk3ODA4Mjc0NF5BMl5BcG5nXkFtZTgwNDc1MzQ2OTE@._V1_.png\"  width = \"40%\" alt=\"404 image\" />\n",
    "\n",
    "In this exercise, you will carry out sentiment analysis on a real corpus, [the IMDB movie review dataset](https://www.kaggle.com/utathya/imdb-review-dataset).\n",
    "The starter code below loads the data CSV file (assuming that it's in the data directory) as a pandas DataFrame called `imdb_df`.\n",
    "\n",
    "We have done a bit of preprocessing on the dataset and we will use the train/test split that's already provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>The world is facing imminent destruction and a...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>What a horrible comedy. Totally lame. The supp...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>Follow-up to 1973's far better \"Cleopatra Jone...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>It was the Sixties, and anyone with long hair ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>this movie begins with an ordinary funeral... ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    type                                             review label\n",
       "0  train  The world is facing imminent destruction and a...   neg\n",
       "1  train  What a horrible comedy. Totally lame. The supp...   neg\n",
       "2  train  Follow-up to 1973's far better \"Cleopatra Jone...   neg\n",
       "3  train  It was the Sixties, and anyone with long hair ...   neg\n",
       "4  train  this movie begins with an ordinary funeral... ...   neg"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_df = pd.read_csv(\"data/imdb_speed.csv\")\n",
    "train_df = imdb_df[imdb_df['type'] == \"train\"]\n",
    "test_df = imdb_df[imdb_df['type'] == \"test\"]\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.1** <br> {points: 1}  \n",
    "\n",
    "Let's now separate our feature vectors from the target.\n",
    "\n",
    "Use the column `review` as your `X` and the `label` column as your target `y`. \n",
    "\n",
    "You will need to do this for both `train_df` and `test_df`.\n",
    "\n",
    "Save the results in objects named `X_train`, `y_train`, `X_test` and `y_test`. \n",
    "\n",
    "(Makes sure that all 4 of these objects are of type Pandas Series. We will be using `CountVectorizer` for future questions and this transformation requires an input of Pandas Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0e78c6cf5da63d77e76227158eb6161f",
     "grade": false,
     "grade_id": "cell-e2813ca2b1b4df7d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X_train = train_df.loc[:,'review']\n",
    "y_train = train_df.loc[:,'label']\n",
    "X_test = test_df.loc[:,'review']\n",
    "y_test = test_df.loc[:,'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3d10e6491bf23a70f3fac0144b0d694a",
     "grade": true,
     "grade_id": "cell-de9b99c573bdb428",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1_1(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.2** <br> {points: 1}  \n",
    "\n",
    "What is the distribution of target values (`label`) in the train split? Your answer should be of type Pandas Series and saved in an object named `class_dist`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c8ec1841722fab35463d9646f3264757",
     "grade": false,
     "grade_id": "cell-a4221b3dc49430cc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class_dist = train_df.groupby('label').size() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "80393b3a0e1a87ae8695e9170599e303",
     "grade": true,
     "grade_id": "cell-dc5e6a320bf78d16",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1_2(class_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.3** <br> {points: 1}  \n",
    "\n",
    "Do any of your columns have any null values? \n",
    "\n",
    "A) Yes\n",
    "\n",
    "B) No\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between `\"\"`, assign the correct answer to an object called `answer1_3`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "91d22cd3e69d89097fb7c970754e7632",
     "grade": false,
     "grade_id": "cell-a80b52675ea3f75e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer1_3 = 'B'\n",
    "answer1_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ab1054bc7d56380cece8dceb22a3a3cc",
     "grade": true,
     "grade_id": "cell-afed4860b4dadd44",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1_3(answer1_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.4** <br> {points: 2}  \n",
    "\n",
    "***Challenge question!***\n",
    "\n",
    "How many words are present in each review? \n",
    "\n",
    "Add a column `review_wordcount` to the `train_df` dataframe and save this new dataframe as an object named `review_length_df`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3067a827edf8e5513b87b108ea751bc7",
     "grade": false,
     "grade_id": "cell-1726fe6021386d28",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "review_length_df = train_df.assign(review_wordcount = train_df['review'].apply(str.split).apply(len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "de075eafcb94246e6e5f7944d362c57d",
     "grade": true,
     "grade_id": "cell-b38989bc28be88a3",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1_4(review_length_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.5** <br> {points: 3}  \n",
    "\n",
    "What is the average word count for each review label (pos and neg)?\n",
    "\n",
    "Save the average negative label word count and the average positive label word count to the nearest full number in objects named `neg_wc_avg` and `pos_wc_avg` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "27b8d8a06bcbe59e64e1434d555c0897",
     "grade": false,
     "grade_id": "cell-ccb66cda36fd0f91",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative word count avg.: 234.0    Positive word count avg.: 238.0\n"
     ]
    }
   ],
   "source": [
    "neg_wc_avg = review_length_df[review_length_df['label']=='neg']['review_wordcount'].mean().round()\n",
    "pos_wc_avg = review_length_df[review_length_df['label']=='pos']['review_wordcount'].mean().round()\n",
    "print('Negative word count avg.:', neg_wc_avg,'   Positive word count avg.:',pos_wc_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e72262f36389dfd86f56c252845ddbdd",
     "grade": true,
     "grade_id": "cell-4e4215014acc2d2e",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# check that the variable exists\n",
    "assert 'neg_wc_avg' in globals(\n",
    "), \"Please make sure that your solution is named 'neg_wc_avg'\"\n",
    "\n",
    "# This test has been intentionally hidden. It will be up to you to decide if your solution\n",
    "# is sufficiently good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "29f3019b4ecef97d60dab3561c735937",
     "grade": true,
     "grade_id": "cell-dfdf48541df7774c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1_5_2(pos_wc_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.6** <br> {points: 2}  \n",
    "\n",
    "Plot the average review wordcount per label in a bar chart. \n",
    "\n",
    "Save the plot in an object named `plot_avg_wc`.\n",
    "\n",
    "Remember to provide a title to your plot as well.\n",
    "\n",
    "*Hint: remember you can plot `groupby` objects and when you do so, you'll need to reset your index.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1110148e238db09fb436e03e03ec2aca",
     "grade": false,
     "grade_id": "cell-70cb229b2af4e588",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-81d9c89fd3f3473ab0490216d2558612\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-81d9c89fd3f3473ab0490216d2558612\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-81d9c89fd3f3473ab0490216d2558612\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-0a10ca987d3d0482f3a265585172d3c1\"}, \"mark\": \"bar\", \"encoding\": {\"x\": {\"type\": \"nominal\", \"field\": \"label\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"review_wordcount\"}}, \"width\": 350, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-0a10ca987d3d0482f3a265585172d3c1\": [{\"label\": \"neg\", \"review_wordcount\": 234}, {\"label\": \"pos\", \"review_wordcount\": 238}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_df = review_length_df.groupby('label').mean().round().astype('int').reset_index()\n",
    "plot_avg_wc = alt.Chart(plot_df, width = 350).mark_bar().encode(x = alt.X('label'), y = alt.Y('review_wordcount'))\n",
    "plot_avg_wc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fe854b84fbd3713378248aeee52cbed5",
     "grade": true,
     "grade_id": "cell-d15d6ded8ce42ef9",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1_6(plot_avg_wc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.7** <br> {points: 1}  \n",
    "\n",
    "Let's make a baseline model using `DummyClassifier`.\n",
    "\n",
    "Build a `DummyClassifier` named `dummy` using `strategy='most_frequent'`. Perform cross-validation on the training portion. Make sure that you return the training score using `return_train_score=True`. \n",
    "\n",
    "Save the results in a dataframe named `dummy_scores`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1fcd19a7d929b20d476a50130b92d4dd",
     "grade": false,
     "grade_id": "cell-21468e80688065c5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "dummy = DummyClassifier(strategy = 'most_frequent')\n",
    "dummy_scores = pd.DataFrame(cross_validate(dummy, X_train, y_train, return_train_score = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a01f0f9b2e76ca787f247a51e6df471d",
     "grade": true,
     "grade_id": "cell-3ae4f9a2e6cc1453",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1_7(dummy_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.8** <br> {points: 0}\n",
    "\n",
    "Import `CountVectorizer` and `LogisticRegression`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1b942243d97b0ab0b1975ed832e9d68c",
     "grade": false,
     "grade_id": "cell-bb57d43dab2cdbf5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c39a7ac636cf6caa2840a5fe532e2bee",
     "grade": true,
     "grade_id": "cell-884574d9f3ed3195",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1_8()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.9** <br> {points: 1}  \n",
    "\n",
    "Build a pipeline named `lr_pipe` that uses the `CountVectorizer()` transformer followed by the logistic regression model (set `max_iter=2000` this will help avoid any warnings).\n",
    "\n",
    "Perform 5 fold cross-validation on the training set using `lr_pipe` and return the training score. Save the results in a dataframe named `lr_scores`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4bf8bd17a8cc7af7cfe278d76a916c14",
     "grade": false,
     "grade_id": "cell-5f01df846f98b34f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "lr_pipe = make_pipeline(CountVectorizer(max_features=100), LogisticRegression(max_iter = 2000))\n",
    "lr_scores = pd.DataFrame(cross_validate(lr_pipe, X_train, y_train, cv = 5, return_train_score = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6fd5d3aa00d2db3f30b56180bd95da74",
     "grade": true,
     "grade_id": "cell-62e4194474333507",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1_9(lr_pipe,lr_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.10** <br> {points: 1} \n",
    "\n",
    "What is the mean of each column in `lr_scores`?\n",
    "\n",
    "Save your result in an object named `lr_mean`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d765dba1dd19717ec97ff364b57e3afb",
     "grade": false,
     "grade_id": "cell-49d3f6f99089b4dd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "lr_mean = lr_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "71195c46fee15811c051238cb50780da",
     "grade": true,
     "grade_id": "cell-21515470d3758502",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1_10(lr_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.11** <br> {points: 1}  \n",
    "\n",
    "Which model performs better? \n",
    "\n",
    "A) `DummyClassifier`\n",
    "\n",
    "B) `LogisticRegression`\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between `\"\"`, assign the correct answer to an object called `answer1_11`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6797f61eb1d1c2c0b417316607d7cd92",
     "grade": false,
     "grade_id": "cell-ac18a6619cc03429",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer1_11 = 'B'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "826a6045acae93adb7f33299782e6a31",
     "grade": true,
     "grade_id": "cell-5e08f691bef0f241",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1_11(answer1_11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.12** <br> {points: 2} \n",
    "\n",
    "Let's see if we can optimize our model by hyperparameter tuning both `max_features` and `C`. \n",
    "\n",
    "First, let's answer the following questions. \n",
    "\n",
    "i) Does `max_features` correspond to a hyperparameter for `CountVectorizer` or `LogisticRegression`? Answer the name in an object named `max_f_hyper`.\n",
    "\n",
    "ii) Does `C` correspond to a hyperparameter for `CountVectorizer` or `LogisticRegression`? Answer the name in an object named `C_hyper`.\n",
    "\n",
    "*Answer in the cell below by specifying either \"CountVectorizer\" or \"LogisticRegression\" for the objects named in the above question. Make sure your answer is between `\"\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9607196a820e6a9d37418065019cb3f9",
     "grade": false,
     "grade_id": "cell-509fe358c804db31",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "max_f_hyper = 'CountVectorizer'\n",
    "C_hyper = 'LogisticRegression'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c1306d02d02830248312a2b558fcc555",
     "grade": true,
     "grade_id": "cell-f78d6830b977e12e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1_12_1(max_f_hyper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d2641f5933dc0f6ff8f0b2576b120c50",
     "grade": true,
     "grade_id": "cell-f9d746773a3b8e2a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1_12_2(C_hyper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.13** <br> {points: 1} \n",
    "\n",
    "If we increase the `C` hyperparameter values, is that more likely to result in a model that is overfitted or underfitted? \n",
    "\n",
    "*Answer in the cell below by specifying either \"overfitted\" or \"underfitted\" in an object named `answer_1_13`. Make sure your answer is between `\"\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b7bd2746e0bdc65fd62d3cf9f7e2b7ed",
     "grade": false,
     "grade_id": "cell-796d393b70bee261",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer_1_13 = 'overfitted'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cbaf48c17bdc01aeee23b8f878c0da41",
     "grade": true,
     "grade_id": "cell-9b51ac5ffe66192f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1_13(answer_1_13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.14** <br> {points: 1}\n",
    "\n",
    "The time has come to hyperparameter tune! Define a pipeline with `CountVectorizer` and `LogisticRegression` with `max_iter=1000`. Name the pipeline `main_pipe`. \n",
    "\n",
    "Use `RandomizedSearchCV` to jointly optimize the hyperparameters in the `params_grid` that we have provided for you. \n",
    "Name this object `random_search`. Specify `n_iter=10`, `cv=5`, `random_state=888`, `n_jobs=-1`, `verbose=3`, and `return_train_score=True`. \n",
    "Make sure to fit your model on the training portion of the IMDB dataset. \n",
    "\n",
    "This can take quite a while (10 minutes for me!) so please be patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"logisticregression__C\": loguniform(0.01, 100),\n",
    "    \"countvectorizer__max_features\": randint(10, 1000),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b9b813ddc61ba79584347ff625b0060c",
     "grade": false,
     "grade_id": "cell-84e687666b1a490f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 1/5] END countvectorizer__max_features=520, logisticregression__C=3.127595166460435;, score=(train=0.858, test=0.818) total time=   3.2s\n",
      "[CV 2/5] END countvectorizer__max_features=520, logisticregression__C=3.127595166460435;, score=(train=0.861, test=0.815) total time=   3.4s\n",
      "[CV 3/5] END countvectorizer__max_features=520, logisticregression__C=3.127595166460435;, score=(train=0.862, test=0.818) total time=   3.2s\n",
      "[CV 4/5] END countvectorizer__max_features=520, logisticregression__C=3.127595166460435;, score=(train=0.862, test=0.822) total time=   3.1s\n",
      "[CV 5/5] END countvectorizer__max_features=520, logisticregression__C=3.127595166460435;, score=(train=0.856, test=0.836) total time=   3.2s\n",
      "[CV 1/5] END countvectorizer__max_features=249, logisticregression__C=0.8588233360393741;, score=(train=0.806, test=0.775) total time=   3.0s\n",
      "[CV 2/5] END countvectorizer__max_features=249, logisticregression__C=0.8588233360393741;, score=(train=0.807, test=0.784) total time=   2.7s\n",
      "[CV 3/5] END countvectorizer__max_features=249, logisticregression__C=0.8588233360393741;, score=(train=0.805, test=0.790) total time=   2.8s\n",
      "[CV 4/5] END countvectorizer__max_features=249, logisticregression__C=0.8588233360393741;, score=(train=0.805, test=0.789) total time=   2.7s\n",
      "[CV 5/5] END countvectorizer__max_features=249, logisticregression__C=0.8588233360393741;, score=(train=0.801, test=0.797) total time=   2.7s\n",
      "[CV 1/5] END countvectorizer__max_features=369, logisticregression__C=0.024075609796438913;, score=(train=0.831, test=0.797) total time=   2.7s\n",
      "[CV 2/5] END countvectorizer__max_features=369, logisticregression__C=0.024075609796438913;, score=(train=0.827, test=0.808) total time=   2.8s\n",
      "[CV 3/5] END countvectorizer__max_features=369, logisticregression__C=0.024075609796438913;, score=(train=0.831, test=0.818) total time=   2.8s\n",
      "[CV 4/5] END countvectorizer__max_features=369, logisticregression__C=0.024075609796438913;, score=(train=0.829, test=0.805) total time=   2.8s\n",
      "[CV 5/5] END countvectorizer__max_features=369, logisticregression__C=0.024075609796438913;, score=(train=0.824, test=0.820) total time=   2.8s\n",
      "[CV 1/5] END countvectorizer__max_features=710, logisticregression__C=0.016976195590890333;, score=(train=0.867, test=0.831) total time=   2.8s\n",
      "[CV 2/5] END countvectorizer__max_features=710, logisticregression__C=0.016976195590890333;, score=(train=0.865, test=0.838) total time=   2.7s\n",
      "[CV 3/5] END countvectorizer__max_features=710, logisticregression__C=0.016976195590890333;, score=(train=0.865, test=0.832) total time=   2.8s\n",
      "[CV 4/5] END countvectorizer__max_features=710, logisticregression__C=0.016976195590890333;, score=(train=0.863, test=0.832) total time=   2.8s\n",
      "[CV 5/5] END countvectorizer__max_features=710, logisticregression__C=0.016976195590890333;, score=(train=0.864, test=0.847) total time=   2.7s\n",
      "[CV 1/5] END countvectorizer__max_features=410, logisticregression__C=0.08489093942377351;, score=(train=0.845, test=0.819) total time=   3.2s\n",
      "[CV 2/5] END countvectorizer__max_features=410, logisticregression__C=0.08489093942377351;, score=(train=0.841, test=0.808) total time=   2.8s\n",
      "[CV 3/5] END countvectorizer__max_features=410, logisticregression__C=0.08489093942377351;, score=(train=0.840, test=0.823) total time=   2.9s\n",
      "[CV 4/5] END countvectorizer__max_features=410, logisticregression__C=0.08489093942377351;, score=(train=0.841, test=0.815) total time=   2.8s\n",
      "[CV 5/5] END countvectorizer__max_features=410, logisticregression__C=0.08489093942377351;, score=(train=0.836, test=0.822) total time=   2.9s\n",
      "[CV 1/5] END countvectorizer__max_features=874, logisticregression__C=0.03402603563390611;, score=(train=0.882, test=0.844) total time=   3.0s\n",
      "[CV 2/5] END countvectorizer__max_features=874, logisticregression__C=0.03402603563390611;, score=(train=0.884, test=0.849) total time=   3.7s\n",
      "[CV 3/5] END countvectorizer__max_features=874, logisticregression__C=0.03402603563390611;, score=(train=0.885, test=0.847) total time=   4.1s\n",
      "[CV 4/5] END countvectorizer__max_features=874, logisticregression__C=0.03402603563390611;, score=(train=0.884, test=0.849) total time=   3.4s\n",
      "[CV 5/5] END countvectorizer__max_features=874, logisticregression__C=0.03402603563390611;, score=(train=0.884, test=0.846) total time=   3.0s\n",
      "[CV 1/5] END countvectorizer__max_features=986, logisticregression__C=8.01031006424307;, score=(train=0.901, test=0.833) total time=   4.0s\n",
      "[CV 2/5] END countvectorizer__max_features=986, logisticregression__C=8.01031006424307;, score=(train=0.905, test=0.826) total time=   4.9s\n",
      "[CV 3/5] END countvectorizer__max_features=986, logisticregression__C=8.01031006424307;, score=(train=0.904, test=0.832) total time=   6.8s\n",
      "[CV 4/5] END countvectorizer__max_features=986, logisticregression__C=8.01031006424307;, score=(train=0.902, test=0.833) total time=   6.8s\n",
      "[CV 5/5] END countvectorizer__max_features=986, logisticregression__C=8.01031006424307;, score=(train=0.904, test=0.831) total time=   5.2s\n",
      "[CV 1/5] END countvectorizer__max_features=413, logisticregression__C=0.09850535344353391;, score=(train=0.845, test=0.815) total time=   2.9s\n",
      "[CV 2/5] END countvectorizer__max_features=413, logisticregression__C=0.09850535344353391;, score=(train=0.842, test=0.809) total time=   4.1s\n",
      "[CV 3/5] END countvectorizer__max_features=413, logisticregression__C=0.09850535344353391;, score=(train=0.840, test=0.826) total time=   4.3s\n",
      "[CV 4/5] END countvectorizer__max_features=413, logisticregression__C=0.09850535344353391;, score=(train=0.840, test=0.816) total time=   3.0s\n",
      "[CV 5/5] END countvectorizer__max_features=413, logisticregression__C=0.09850535344353391;, score=(train=0.838, test=0.819) total time=   2.8s\n",
      "[CV 1/5] END countvectorizer__max_features=824, logisticregression__C=0.020389214792861758;, score=(train=0.875, test=0.842) total time=   3.6s\n",
      "[CV 2/5] END countvectorizer__max_features=824, logisticregression__C=0.020389214792861758;, score=(train=0.876, test=0.841) total time=   3.0s\n",
      "[CV 3/5] END countvectorizer__max_features=824, logisticregression__C=0.020389214792861758;, score=(train=0.877, test=0.840) total time=   3.9s\n",
      "[CV 4/5] END countvectorizer__max_features=824, logisticregression__C=0.020389214792861758;, score=(train=0.875, test=0.842) total time=   3.8s\n",
      "[CV 5/5] END countvectorizer__max_features=824, logisticregression__C=0.020389214792861758;, score=(train=0.876, test=0.848) total time=   2.8s\n",
      "[CV 1/5] END countvectorizer__max_features=190, logisticregression__C=31.38036417480889;, score=(train=0.777, test=0.751) total time=   2.6s\n",
      "[CV 2/5] END countvectorizer__max_features=190, logisticregression__C=31.38036417480889;, score=(train=0.782, test=0.765) total time=   2.6s\n",
      "[CV 3/5] END countvectorizer__max_features=190, logisticregression__C=31.38036417480889;, score=(train=0.775, test=0.769) total time=   2.5s\n",
      "[CV 4/5] END countvectorizer__max_features=190, logisticregression__C=31.38036417480889;, score=(train=0.780, test=0.768) total time=   3.2s\n",
      "[CV 5/5] END countvectorizer__max_features=190, logisticregression__C=31.38036417480889;, score=(train=0.776, test=0.767) total time=   3.5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('countvectorizer',\n",
       "                                              CountVectorizer()),\n",
       "                                             ('logisticregression',\n",
       "                                              LogisticRegression(max_iter=1000))]),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'countvectorizer__max_features': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fc7846ba550>,\n",
       "                                        'logisticregression__C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fc7846ba280>},\n",
       "                   random_state=888, return_train_score=True, verbose=3)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_pipe = make_pipeline(CountVectorizer(), LogisticRegression(max_iter = 1000))\n",
    "random_search = RandomizedSearchCV(main_pipe, param_grid, cv = 5, n_iter = 10, return_train_score = True, random_state = 888, n_jobs = -1, verbose = 3)\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_countvectorizer__max_features</th>\n",
       "      <th>param_logisticregression__C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.779353</td>\n",
       "      <td>0.101595</td>\n",
       "      <td>0.458722</td>\n",
       "      <td>0.006991</td>\n",
       "      <td>520</td>\n",
       "      <td>3.127595</td>\n",
       "      <td>{'countvectorizer__max_features': 520, 'logist...</td>\n",
       "      <td>0.8175</td>\n",
       "      <td>0.8145</td>\n",
       "      <td>0.8175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8214</td>\n",
       "      <td>0.007632</td>\n",
       "      <td>5</td>\n",
       "      <td>0.858125</td>\n",
       "      <td>0.860625</td>\n",
       "      <td>0.861500</td>\n",
       "      <td>0.861750</td>\n",
       "      <td>0.856250</td>\n",
       "      <td>0.859650</td>\n",
       "      <td>0.002129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.371051</td>\n",
       "      <td>0.117120</td>\n",
       "      <td>0.432759</td>\n",
       "      <td>0.005962</td>\n",
       "      <td>249</td>\n",
       "      <td>0.858823</td>\n",
       "      <td>{'countvectorizer__max_features': 249, 'logist...</td>\n",
       "      <td>0.7755</td>\n",
       "      <td>0.7845</td>\n",
       "      <td>0.7900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7872</td>\n",
       "      <td>0.007089</td>\n",
       "      <td>9</td>\n",
       "      <td>0.805625</td>\n",
       "      <td>0.807250</td>\n",
       "      <td>0.805000</td>\n",
       "      <td>0.805125</td>\n",
       "      <td>0.800625</td>\n",
       "      <td>0.804725</td>\n",
       "      <td>0.002201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.314539</td>\n",
       "      <td>0.055958</td>\n",
       "      <td>0.449499</td>\n",
       "      <td>0.005251</td>\n",
       "      <td>369</td>\n",
       "      <td>0.024076</td>\n",
       "      <td>{'countvectorizer__max_features': 369, 'logist...</td>\n",
       "      <td>0.7975</td>\n",
       "      <td>0.8085</td>\n",
       "      <td>0.8175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8097</td>\n",
       "      <td>0.008060</td>\n",
       "      <td>8</td>\n",
       "      <td>0.831250</td>\n",
       "      <td>0.826625</td>\n",
       "      <td>0.831000</td>\n",
       "      <td>0.829375</td>\n",
       "      <td>0.824250</td>\n",
       "      <td>0.828500</td>\n",
       "      <td>0.002689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.304008</td>\n",
       "      <td>0.047424</td>\n",
       "      <td>0.467048</td>\n",
       "      <td>0.007182</td>\n",
       "      <td>710</td>\n",
       "      <td>0.016976</td>\n",
       "      <td>{'countvectorizer__max_features': 710, 'logist...</td>\n",
       "      <td>0.8310</td>\n",
       "      <td>0.8380</td>\n",
       "      <td>0.8320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8358</td>\n",
       "      <td>0.005921</td>\n",
       "      <td>3</td>\n",
       "      <td>0.867000</td>\n",
       "      <td>0.864500</td>\n",
       "      <td>0.865250</td>\n",
       "      <td>0.863375</td>\n",
       "      <td>0.863750</td>\n",
       "      <td>0.864775</td>\n",
       "      <td>0.001285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.473778</td>\n",
       "      <td>0.138619</td>\n",
       "      <td>0.454355</td>\n",
       "      <td>0.006693</td>\n",
       "      <td>410</td>\n",
       "      <td>0.084891</td>\n",
       "      <td>{'countvectorizer__max_features': 410, 'logist...</td>\n",
       "      <td>0.8190</td>\n",
       "      <td>0.8085</td>\n",
       "      <td>0.8225</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8172</td>\n",
       "      <td>0.005154</td>\n",
       "      <td>6</td>\n",
       "      <td>0.845125</td>\n",
       "      <td>0.841000</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.840750</td>\n",
       "      <td>0.835875</td>\n",
       "      <td>0.840550</td>\n",
       "      <td>0.002944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.903542</td>\n",
       "      <td>0.319727</td>\n",
       "      <td>0.544354</td>\n",
       "      <td>0.094868</td>\n",
       "      <td>874</td>\n",
       "      <td>0.034026</td>\n",
       "      <td>{'countvectorizer__max_features': 874, 'logist...</td>\n",
       "      <td>0.8440</td>\n",
       "      <td>0.8485</td>\n",
       "      <td>0.8470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8468</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>1</td>\n",
       "      <td>0.882125</td>\n",
       "      <td>0.883875</td>\n",
       "      <td>0.884625</td>\n",
       "      <td>0.883750</td>\n",
       "      <td>0.883875</td>\n",
       "      <td>0.883650</td>\n",
       "      <td>0.000823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.029576</td>\n",
       "      <td>1.016763</td>\n",
       "      <td>0.530940</td>\n",
       "      <td>0.084579</td>\n",
       "      <td>986</td>\n",
       "      <td>8.01031</td>\n",
       "      <td>{'countvectorizer__max_features': 986, 'logist...</td>\n",
       "      <td>0.8330</td>\n",
       "      <td>0.8255</td>\n",
       "      <td>0.8315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8308</td>\n",
       "      <td>0.002768</td>\n",
       "      <td>4</td>\n",
       "      <td>0.901500</td>\n",
       "      <td>0.904750</td>\n",
       "      <td>0.904000</td>\n",
       "      <td>0.901875</td>\n",
       "      <td>0.903750</td>\n",
       "      <td>0.903175</td>\n",
       "      <td>0.001264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.859670</td>\n",
       "      <td>0.489682</td>\n",
       "      <td>0.583782</td>\n",
       "      <td>0.185353</td>\n",
       "      <td>413</td>\n",
       "      <td>0.098505</td>\n",
       "      <td>{'countvectorizer__max_features': 413, 'logist...</td>\n",
       "      <td>0.8145</td>\n",
       "      <td>0.8095</td>\n",
       "      <td>0.8255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8168</td>\n",
       "      <td>0.005250</td>\n",
       "      <td>7</td>\n",
       "      <td>0.845000</td>\n",
       "      <td>0.841625</td>\n",
       "      <td>0.839750</td>\n",
       "      <td>0.840375</td>\n",
       "      <td>0.838000</td>\n",
       "      <td>0.840950</td>\n",
       "      <td>0.002338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.930940</td>\n",
       "      <td>0.419166</td>\n",
       "      <td>0.496799</td>\n",
       "      <td>0.063215</td>\n",
       "      <td>824</td>\n",
       "      <td>0.020389</td>\n",
       "      <td>{'countvectorizer__max_features': 824, 'logist...</td>\n",
       "      <td>0.8420</td>\n",
       "      <td>0.8410</td>\n",
       "      <td>0.8400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8425</td>\n",
       "      <td>0.002608</td>\n",
       "      <td>2</td>\n",
       "      <td>0.875375</td>\n",
       "      <td>0.875750</td>\n",
       "      <td>0.877250</td>\n",
       "      <td>0.875125</td>\n",
       "      <td>0.876125</td>\n",
       "      <td>0.875925</td>\n",
       "      <td>0.000744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.392976</td>\n",
       "      <td>0.327179</td>\n",
       "      <td>0.499454</td>\n",
       "      <td>0.076963</td>\n",
       "      <td>190</td>\n",
       "      <td>31.380364</td>\n",
       "      <td>{'countvectorizer__max_features': 190, 'logist...</td>\n",
       "      <td>0.7510</td>\n",
       "      <td>0.7655</td>\n",
       "      <td>0.7690</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7641</td>\n",
       "      <td>0.006651</td>\n",
       "      <td>10</td>\n",
       "      <td>0.777500</td>\n",
       "      <td>0.782250</td>\n",
       "      <td>0.775250</td>\n",
       "      <td>0.779750</td>\n",
       "      <td>0.776375</td>\n",
       "      <td>0.778225</td>\n",
       "      <td>0.002503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       2.779353      0.101595         0.458722        0.006991   \n",
       "1       2.371051      0.117120         0.432759        0.005962   \n",
       "2       2.314539      0.055958         0.449499        0.005251   \n",
       "3       2.304008      0.047424         0.467048        0.007182   \n",
       "4       2.473778      0.138619         0.454355        0.006693   \n",
       "5       2.903542      0.319727         0.544354        0.094868   \n",
       "6       5.029576      1.016763         0.530940        0.084579   \n",
       "7       2.859670      0.489682         0.583782        0.185353   \n",
       "8       2.930940      0.419166         0.496799        0.063215   \n",
       "9       2.392976      0.327179         0.499454        0.076963   \n",
       "\n",
       "  param_countvectorizer__max_features param_logisticregression__C  \\\n",
       "0                                 520                    3.127595   \n",
       "1                                 249                    0.858823   \n",
       "2                                 369                    0.024076   \n",
       "3                                 710                    0.016976   \n",
       "4                                 410                    0.084891   \n",
       "5                                 874                    0.034026   \n",
       "6                                 986                     8.01031   \n",
       "7                                 413                    0.098505   \n",
       "8                                 824                    0.020389   \n",
       "9                                 190                   31.380364   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'countvectorizer__max_features': 520, 'logist...             0.8175   \n",
       "1  {'countvectorizer__max_features': 249, 'logist...             0.7755   \n",
       "2  {'countvectorizer__max_features': 369, 'logist...             0.7975   \n",
       "3  {'countvectorizer__max_features': 710, 'logist...             0.8310   \n",
       "4  {'countvectorizer__max_features': 410, 'logist...             0.8190   \n",
       "5  {'countvectorizer__max_features': 874, 'logist...             0.8440   \n",
       "6  {'countvectorizer__max_features': 986, 'logist...             0.8330   \n",
       "7  {'countvectorizer__max_features': 413, 'logist...             0.8145   \n",
       "8  {'countvectorizer__max_features': 824, 'logist...             0.8420   \n",
       "9  {'countvectorizer__max_features': 190, 'logist...             0.7510   \n",
       "\n",
       "   split1_test_score  split2_test_score  ...  mean_test_score  std_test_score  \\\n",
       "0             0.8145             0.8175  ...           0.8214        0.007632   \n",
       "1             0.7845             0.7900  ...           0.7872        0.007089   \n",
       "2             0.8085             0.8175  ...           0.8097        0.008060   \n",
       "3             0.8380             0.8320  ...           0.8358        0.005921   \n",
       "4             0.8085             0.8225  ...           0.8172        0.005154   \n",
       "5             0.8485             0.8470  ...           0.8468        0.001860   \n",
       "6             0.8255             0.8315  ...           0.8308        0.002768   \n",
       "7             0.8095             0.8255  ...           0.8168        0.005250   \n",
       "8             0.8410             0.8400  ...           0.8425        0.002608   \n",
       "9             0.7655             0.7690  ...           0.7641        0.006651   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                5            0.858125            0.860625   \n",
       "1                9            0.805625            0.807250   \n",
       "2                8            0.831250            0.826625   \n",
       "3                3            0.867000            0.864500   \n",
       "4                6            0.845125            0.841000   \n",
       "5                1            0.882125            0.883875   \n",
       "6                4            0.901500            0.904750   \n",
       "7                7            0.845000            0.841625   \n",
       "8                2            0.875375            0.875750   \n",
       "9               10            0.777500            0.782250   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0            0.861500            0.861750            0.856250   \n",
       "1            0.805000            0.805125            0.800625   \n",
       "2            0.831000            0.829375            0.824250   \n",
       "3            0.865250            0.863375            0.863750   \n",
       "4            0.840000            0.840750            0.835875   \n",
       "5            0.884625            0.883750            0.883875   \n",
       "6            0.904000            0.901875            0.903750   \n",
       "7            0.839750            0.840375            0.838000   \n",
       "8            0.877250            0.875125            0.876125   \n",
       "9            0.775250            0.779750            0.776375   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "0          0.859650         0.002129  \n",
       "1          0.804725         0.002201  \n",
       "2          0.828500         0.002689  \n",
       "3          0.864775         0.001285  \n",
       "4          0.840550         0.002944  \n",
       "5          0.883650         0.000823  \n",
       "6          0.903175         0.001264  \n",
       "7          0.840950         0.002338  \n",
       "8          0.875925         0.000744  \n",
       "9          0.778225         0.002503  \n",
       "\n",
       "[10 rows x 22 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ebfd094cc762d4759551bc33eb71422d",
     "grade": true,
     "grade_id": "cell-d3c5d0c38998206d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1_14(main_pipe,random_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.15** <br> {points: 3}\n",
    "\n",
    "What are the best hyperparameter values found by `RandomizedSearchCV` for `C` and `max_features`. Save it in an object named `optimal_parameters`. (The grader is expecting a dictionary object) \n",
    "\n",
    "What was the corresponding validation score? Save this in an object named `optimal_score`. \n",
    "\n",
    "*Hint: `.best_params_`  and `.best_score_` are helpful here.* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "09af9afc61d82e0d5dcf5ad23d384ac4",
     "grade": false,
     "grade_id": "cell-bf31b1fe29c0d5fd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8468"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_parameters = random_search.best_params_\n",
    "optimal_score = random_search.best_score_\n",
    "optimal_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "debb32e39a383f7342d843f3cc9f8bf8",
     "grade": true,
     "grade_id": "cell-b1dca3ab89397234",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# check that the variable exists\n",
    "assert 'optimal_parameters' in globals(\n",
    "), \"Please make sure that your solution is named 'optimal_parameters'\"\n",
    "\n",
    "# This test has been intentionally hidden. It will be up to you to decide if your solution\n",
    "# is sufficiently good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bef3101c07c3737412d8871e65cdf9ab",
     "grade": true,
     "grade_id": "cell-d4e6b241d1082f4f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1_15_2(random_search, optimal_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.16** <br> {points: 1}\n",
    "\n",
    "Are you getting a better mean validation score than logistic regression pipeline with default hyperparameters from 1.9? \n",
    "\n",
    "A) Yes\n",
    "\n",
    "B) No\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between `\"\"`, assign the correct answer to an object called `answer1_16`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fb39e7d288c510b3078e16e638be70e6",
     "grade": false,
     "grade_id": "cell-29d75a60f3f9b0d6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer1_16 = 'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "447079e2e9d939b00b97909acf2ed2aa",
     "grade": true,
     "grade_id": "cell-6ad27d5574dc3a1d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1_16(answer1_16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model Interpretation <a name=\"4\"></a>\n",
    "<hr>\n",
    "\n",
    "One of the primary advantages of linear models is their ability to interpret models in terms of important features. In this exercise, we'll explore the coefficients learned by logistic regression classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.1** <br> {points: 1}\n",
    "\n",
    "Use `best_estimator_` to find the best estimator of `random_search` from 1.14 and save it in an object named `best_model`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c2b40b7a030f0f20f48ea47130d21b89",
     "grade": false,
     "grade_id": "cell-5406b2e78549d105",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvectorizer', CountVectorizer(max_features=874)),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(C=0.03402603563390611, max_iter=1000))])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = random_search.best_estimator_\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e1961c457fa94334b9d4b0009f249ce2",
     "grade": true,
     "grade_id": "cell-f539c53563023387",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2_1(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2** <br> {points: 1}\n",
    "\n",
    "Use `coef_` to find the coefficients of the features. This information is exposed by the `coef_` attribute of [LogisticRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) object. (*Hint: You'll have to reference `logisticregression` from the `best_model` object because `best_model` is a `Pipeline` object*.\n",
    "\n",
    "Name this object `lr_coeffs`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1d49bf838949ed888a7a1274b5fe5294",
     "grade": false,
     "grade_id": "cell-26b0b4fa95ef0621",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_coeffs = best_model['logisticregression'].coef_\n",
    "round(max(lr_coeffs[0]),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8d10989d0e50c9ebe8d18324d8c77b8f",
     "grade": true,
     "grade_id": "cell-37e4cd094699c2d1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2_2(lr_coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3** <br> {points: 1}\n",
    "\n",
    "Find the features that `CountVectorizer` produced by calling `get_feature_names()` on the `CountVectorizer` object within the `best_model` object. \n",
    "(*Hint: You'll have to reference `countvectorizer` from the `best_model` object because `best_model` is a `Pipeline` object*) \n",
    "\n",
    "Save this in an object named `vocab`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2981e966cc55e48545b0bf57fb4cac66",
     "grade": false,
     "grade_id": "cell-90314f78c1e949c7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "vocab = best_model['countvectorizer'].get_feature_names()optimal_parameters = random_search.best_params_\n",
    "optimal_score = random_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "de75e6cd5c9e776829d6574d695728aa",
     "grade": true,
     "grade_id": "cell-079308bed544da66",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2_3(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've provided you the next code which combines the features with its respective feature coefficient (Our gift to you!) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>you</td>\n",
       "      <td>0.109271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>young</td>\n",
       "      <td>0.023149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>your</td>\n",
       "      <td>-0.032813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>yourself</td>\n",
       "      <td>-0.116746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>zombie</td>\n",
       "      <td>0.005472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word coefficient\n",
       "869       you    0.109271\n",
       "870     young    0.023149\n",
       "871      your   -0.032813\n",
       "872  yourself   -0.116746\n",
       "873    zombie    0.005472"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_coef_df = pd.DataFrame(data = [vocab,lr_coeffs.flatten()]).T.rename(columns={0:'word', 1:'coefficient'})\n",
    "vocab_coef_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.4** <br> {points: 1}\n",
    "\n",
    "Find the 10 words whose presence are most indicative of a positive review. Save the words and their corresponding weights in a dataframe ordered from most indicative to least indicative. \n",
    "\n",
    "Save these in a dataframe object named `positive_words`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "95070f19425f497be3bd79f73b7e55be",
     "grade": false,
     "grade_id": "cell-bf0a678aac774e18",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>excellent</td>\n",
       "      <td>0.675848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>wonderful</td>\n",
       "      <td>0.565064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>perfect</td>\n",
       "      <td>0.537209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>amazing</td>\n",
       "      <td>0.527257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>highly</td>\n",
       "      <td>0.47627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>favorite</td>\n",
       "      <td>0.475412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>loved</td>\n",
       "      <td>0.463348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>today</td>\n",
       "      <td>0.437116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>brilliant</td>\n",
       "      <td>0.42925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>great</td>\n",
       "      <td>0.416384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word coefficient\n",
       "231  excellent    0.675848\n",
       "846  wonderful    0.565064\n",
       "546    perfect    0.537209\n",
       "30     amazing    0.527257\n",
       "341     highly     0.47627\n",
       "251   favorite    0.475412\n",
       "439      loved    0.463348\n",
       "760      today    0.437116\n",
       "93   brilliant     0.42925\n",
       "310      great    0.416384"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_coef_df = vocab_coef_df.sort_values('coefficient', ascending=False)\n",
    "positive_words = pos_coef_df.iloc[:10,:]\n",
    "positive_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "67ada55b24d18cee7e8d91cdb028d308",
     "grade": true,
     "grade_id": "cell-27fcdeed004cd23d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2_4(positive_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.5** <br> {points: 1}\n",
    "\n",
    "Find the 10 words whose presence are most indicative of a negative review. Save the words and their corresponding weights in a dataframe ordered from most indicative to least indicative. \n",
    "\n",
    "Save these in a dataframe object named `negative_words`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "58a90462f5767bf71c868e02ac02fdf7",
     "grade": false,
     "grade_id": "cell-40bec17d8594e3be",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>worst</td>\n",
       "      <td>-1.066785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>awful</td>\n",
       "      <td>-0.768064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>waste</td>\n",
       "      <td>-0.745398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>horrible</td>\n",
       "      <td>-0.661008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>terrible</td>\n",
       "      <td>-0.660158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>poorly</td>\n",
       "      <td>-0.653296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>boring</td>\n",
       "      <td>-0.609551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>dull</td>\n",
       "      <td>-0.572556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>poor</td>\n",
       "      <td>-0.568203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>lame</td>\n",
       "      <td>-0.550497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word coefficient\n",
       "854     worst   -1.066785\n",
       "58      awful   -0.768064\n",
       "813     waste   -0.745398\n",
       "351  horrible   -0.661008\n",
       "731  terrible   -0.660158\n",
       "567    poorly   -0.653296\n",
       "89     boring   -0.609551\n",
       "191      dull   -0.572556\n",
       "566      poor   -0.568203\n",
       "403      lame   -0.550497"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_coef_df = vocab_coef_df.sort_values('coefficient', ascending=True)\n",
    "negative_words = neg_coef_df.iloc[:10,:]\n",
    "negative_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1f15dd097db11ce93c0525fcbf503d2c",
     "grade": true,
     "grade_id": "cell-ce053ef7af404102",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2_5(negative_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.6** <br> {points: 2}\n",
    "\n",
    "Do the words associated with positive and negative reviews make sense? \n",
    "\n",
    "\n",
    "A) Yes\n",
    "\n",
    "B) No\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between `\"\"`, assign the correct answer to an object called `answer2_6`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d8a6beb814d5eb831ba35a3c1a472d20",
     "grade": false,
     "grade_id": "cell-fec554d548d920e6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer2_6 = 'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "06ee5ad91730b38f80584126e2e08fc1",
     "grade": true,
     "grade_id": "cell-ae39776298eb0871",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# check that the variable exists\n",
    "assert 'answer2_6' in globals(\n",
    "), \"Please make sure that your solution is named 'answer2_6'\"\n",
    "\n",
    "# This test has been intentionally hidden. It will be up to you to decide if your solution\n",
    "# is sufficiently good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.7** <br> {points: 1}\n",
    "\n",
    "Which of the following statements are true?\n",
    "\n",
    "i) It is useful to access the coefficient values since it helps us interpret the model to some extent.\n",
    "\n",
    "ii) The coefficients help humans to understand which features are the most relevant features for prediction and how they impact the prediction.\n",
    "\n",
    "iii) We can get feature importances for KNN by looking at the corresponding coefficients for each feature.\n",
    "\n",
    "iv) Decision Trees also have a manner of seeing which features are important by looking at the tree and where the splits occur. \n",
    "\n",
    "\n",
    "\n",
    "Select all that apply and add them into a list named `answer_2_7`. \n",
    "For example if statement i and iv are both true, your solution will look like this: \n",
    "\n",
    "```\n",
    "answer_2_7 = [\"i\", \"iv\"] \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fb0090d506991a99c9092df833b0fcc7",
     "grade": false,
     "grade_id": "cell-e123df6d5dee466d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer_2_7 = ['i','ii','iv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a113250e9e49d28d53e1ef72f915ba23",
     "grade": true,
     "grade_id": "cell-885d12270ba61d7b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2_7(answer_2_7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Test score, evaluation and `predict_proba`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.1** <br> {points: 1}\n",
    "\n",
    "Evaluate the best model from `random_search`  on the full training set.\n",
    "\n",
    "Save the score in an object named `training_score`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ab181575bc6745b369ba63317f50a797",
     "grade": false,
     "grade_id": "cell-d8c01ff13c8c4419",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "predict_proba = best_model.fit(X_train, y_train)\n",
    "training_score = predict_proba.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "310cd464111382abf62a0cb7a13eb05c",
     "grade": true,
     "grade_id": "cell-381e18a3118ff7ab",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_3_1(training_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.2** <br> {points: 2}\n",
    "\n",
    "Evaluate this model on the test set. \n",
    "\n",
    "Save the score in an object named `test_score`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eb9f1c7f5f992011594cb3c42b46cb02",
     "grade": false,
     "grade_id": "cell-75684362301480a7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8479"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score = predict_proba.score(X_test, y_test)\n",
    "test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9677add0323b429f4ec5d94df03504de",
     "grade": true,
     "grade_id": "cell-30ab7efc7596ce70",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# check that the variable exists\n",
    "assert 'test_score' in globals(\n",
    "), \"Please make sure that your solution is named 'test_score'\"\n",
    "\n",
    "# This test has been intentionally hidden. It will be up to you to decide if your solution\n",
    "# is sufficiently good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.3** <br> {points: 1}\n",
    "\n",
    "How does your test score compare to the cross validation score `optimal_score` from **Question 1.15**? \n",
    "\n",
    "A) Our model's test score (`test_score`) is much higher than the cross validation score (`optimal_score`).\n",
    "\n",
    "B) Our model's test score (`test_score`) is much lower than the cross validation score (`optimal_score`).\n",
    "\n",
    "C) Our model's test score (`test_score`) is a little higher than the the cross validation score (`optimal_score`).\n",
    "\n",
    "D) Our model's test score (`test_score`) is a little lower than the the cross validation score (`optimal_score`)\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between `\"\"`, assign the correct answer to an object called `answer3_3`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "77e163e3f07c0eedcabbdad699f9b881",
     "grade": false,
     "grade_id": "cell-df0c282f7501bad2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer3_3 = 'C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "29af550efd490f14d5337d907dcd1218",
     "grade": true,
     "grade_id": "cell-bc4abdda953433b6",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_3_3(answer3_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.4** <br> {points: 1}\n",
    "\n",
    "Plot a confusion matrix on the test set using the object `random_search` as your estimator and `normalize=\"all\"` (see the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html) for more help here).\n",
    "\n",
    "Name the plot `reviews_cm`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "79a7ec1f0d07a336b0c789d761593773",
     "grade": false,
     "grade_id": "cell-0fbf22092f07ba56",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "reviews_cm =plot_confusion_matrix(random_search, X_test, y_test, normalize = 'true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d9e3d55c0d5b035277499b42c0b16099",
     "grade": true,
     "grade_id": "cell-77d2298dbbdbe59b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_3_4(reviews_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.5** <br> {points: 3}\n",
    "\n",
    "Print a classification report on the `X_test` predictions of the best model from `random_search` with measurements to 4 decimal places. Use this information to answer the following questions.\n",
    "\n",
    "A) What is the recall if we classify `pos` as our \"positive\" class? Save the result to 4 decimal places in an object named `answer3_5a`. \n",
    "\n",
    "B) What is the precision weighted average? Save the result to 4 decimal places in an object named `answer3_5b`. \n",
    "\n",
    "C) What is the `f1` score using `pos` as your positive class? Save the result to 4 decimal places in an object named `answer3_5c`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.86      0.83      0.85      5000\n",
      "         pos       0.84      0.86      0.85      5000\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.85      0.85      0.85     10000\n",
      "weighted avg       0.85      0.85      0.85     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, random_search.predict(X_test), target_names=[\"neg\", \"pos\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "382c58dca6bca53973f6c467c076c96a",
     "grade": false,
     "grade_id": "cell-28a036c0bedbe347",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer3_5a = 0.86\n",
    "answer3_5b = 0.85\n",
    "answer3_5c = 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f5590966ca4ffae5fc12be3b12de46b2",
     "grade": true,
     "grade_id": "cell-ef83e4c8c671b548",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_3_5_1(answer3_5a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "97d412d4041fb62879f54a7b0cb489c3",
     "grade": true,
     "grade_id": "cell-50eb8166cc91b52e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_3_5_2(answer3_5b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f9adbc22a2dc5f00ecdb266c045fda13",
     "grade": true,
     "grade_id": "cell-69f01092aba39658",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_3_5_3(answer3_5c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.6** <br> {points: 2}\n",
    "\n",
    "Make a dataframe named `results_df` that contains these 5 columns: \n",
    "\n",
    "- `review` - this should contain the reviews from `X_test`.\n",
    "- `true_label` - This should contain the true `y_test` values. \n",
    "- `predicted_y` - The predicted labels generated from `best_model` for the `X_test` reviews. \n",
    "- `neg_label_prob` - The negative probabilities generated from `best_model` for the `X_test` reviews. These can be found at index 0 of the `predict_proba` output (you can get that using `[:,0]`). \n",
    "-  `pos_label_prob` - The negative probabilities generated from `best_model` for the `X_test` reviews. These can be found at index 0 of the `predict_proba` output (you can get that using `[:,1]`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ef699b6cc1eedb086b3181732d55f501",
     "grade": false,
     "grade_id": "cell-fd73ade995c4c656",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10000 entries, 10000 to 19999\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   review          10000 non-null  object \n",
      " 1   true_label      10000 non-null  object \n",
      " 2   predicted_y     10000 non-null  object \n",
      " 3   neg_label_prob  10000 non-null  float64\n",
      " 4   pos_label_prob  10000 non-null  float64\n",
      "dtypes: float64(2), object(3)\n",
      "memory usage: 726.8+ KB\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame({'review' : X_test,\n",
    "              'true_label' : y_test,\n",
    "              'predicted_y' : best_model.predict(X_test),\n",
    "              'neg_label_prob' : best_model.predict_proba(X_test)[:,0],\n",
    "              'pos_label_prob' : best_model.predict_proba(X_test)[:,1]\n",
    "             }\n",
    "                         )\n",
    "results_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a17c40bfd580ac8691a51f29a0467d65",
     "grade": true,
     "grade_id": "cell-c7d6580c13a97fbd",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_3_6(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.7** <br> {points: 1}\n",
    "\n",
    "Find the top 5 movie reviews in `results_df` with the highest predicted probability of being positive (i.e., where the model is most confident that the review is positive).\n",
    "\n",
    "Save the reviews and the associated probability score in a dataframe named `most_pos_df`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fcf976112f3bfc87ba1752ea0e73f79a",
     "grade": false,
     "grade_id": "cell-2efd1cb1fb505acc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>true_label</th>\n",
       "      <th>predicted_y</th>\n",
       "      <th>neg_label_prob</th>\n",
       "      <th>pos_label_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19628</th>\n",
       "      <td>Universal Studios version of \"Flipper\" (1996) ...</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "      <td>6.090454e-08</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15154</th>\n",
       "      <td>This is one of Bruce's most underrated films i...</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "      <td>1.515321e-07</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16447</th>\n",
       "      <td>1904. The North African nation of Morocco is h...</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "      <td>4.482124e-07</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18713</th>\n",
       "      <td>Many years ago I saw this movie (on television...</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "      <td>9.123248e-07</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18332</th>\n",
       "      <td>Ray Charles Robinson (Jamie Foxx) is a extreme...</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "      <td>1.783141e-06</td>\n",
       "      <td>0.999998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review true_label  \\\n",
       "19628  Universal Studios version of \"Flipper\" (1996) ...        pos   \n",
       "15154  This is one of Bruce's most underrated films i...        pos   \n",
       "16447  1904. The North African nation of Morocco is h...        pos   \n",
       "18713  Many years ago I saw this movie (on television...        pos   \n",
       "18332  Ray Charles Robinson (Jamie Foxx) is a extreme...        pos   \n",
       "\n",
       "      predicted_y  neg_label_prob  pos_label_prob  \n",
       "19628         pos    6.090454e-08        1.000000  \n",
       "15154         pos    1.515321e-07        1.000000  \n",
       "16447         pos    4.482124e-07        1.000000  \n",
       "18713         pos    9.123248e-07        0.999999  \n",
       "18332         pos    1.783141e-06        0.999998  "
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_pos_df = pd.DataFrame(results_df.sort_values(by= 'pos_label_prob', ascending = False).head(5))\n",
    "most_pos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bbcf447413876f3d524544ec91b29280",
     "grade": true,
     "grade_id": "cell-0bb36bd74b4871e3",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_3_7(most_pos_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to explore these reviews and see how positive they read!\n",
    "\n",
    "Here is the first one for you (if you got the above question right)! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Universal Studios version of \"Flipper\" (1996) is a great heartwarming film for the entire family with good values and sentimentality. It is the story of Sandy Ricks, a teenager from Chicago who reluctantly spends his vacation with his Uncle Porter Ricks in the Bahamas. This ultimately changes the teenagers life and he grows up in the process. He learns to appreciate nature and to have a respect for the environment. I grew up in the 1960\\'s and the NBC television show \"Flipper\" was my favorite childhood show. Elijah Wood is perfectly cast as a 1990\\'s Sandy Ricks and gives an excellent performance. As much as I liked the NBC television show and MGM theatrical feature films with Luke Halpin as Sandy in the 1960\\'s I liked this feature the best! I feel Elijah Wood is the best Sandy Ricks. With respect to Luke Halpin I feel Elijah Wood has more of a range of acting talent and emotes more as an actor which makes his performance excellent and more believable. I think Elijah Wood is the best young actor working today in films. Director Alan Shapiro also wrote the screenplay and has done an excellent job as both writer and director of this film. Paul Hogan gives a comical and likable performance as Sandy\\'s Uncle Porter Ricks. Mr. Hogan\\'s performance perfectly offsets Elijah\\'s role as Sandy. I am a big fan of underwater films. This film was beautifully shot in the Bahamas like \"Thunderball\" (1965 UA) was. The director of photography was Bill Butler A.S.C. who lensed the film \"Jaws\" in 1975. Mr. Butler is a very talented cinematographer. The underwater director of photography was Pete Romano. He did a superb job with the underwater cinematography. I enjoyed the film score by Joel McNeely. This good film score featured Crosby, Stills and Nash among other talented artists. This motion picture was shot in Panavision like \"Thunderball\" in the aspect ratio of 2.35:1 If possible try to see this film in a scope version as originally framed and visioned by Alan Shapiro and Bill Butler. Another very nice thing is that Mr. Shapiro gave the \"original\" Sandy Ricks (Luke Halpin) a small part in this remake. He portrayed Bounty Fisherman #3 in this film. This was a very kind gesture on Mr. Shapiro\\'s part! As you can tell I am a real true fan of this film. Sadly this beautiful film was met with harsh words by the majority of movie critics. I originally saw this movie on my birthday, May 31st of 1996 in a movie theater. It meant a lot to me. I have it on numerous video versions. The VHS versions are in \"pan and scan\". The laserdisc version is \"letterboxed\" 2.35:1! I even have a VCD in 2.35:1 from Hong Kong which is \"letterboxed\". But my most prized possession is an \"original\" 16mm theatrical feature print which I will treasure for the rest of my life! Thank you Mr. Shapiro, Elijah Wood, Paul Hogan and everyone involved for making this a memorable movie for me to enjoy!<br /><br />P.S. I must add that the quality of the Universal DVD is superb! It is the best DVD as far as quality I have ever seen. The color and resolution is spectacular. The soundtrack is great. I think Universal must have used the same transfer for the DVD that they did for the laserdisc version. The 35mm scope print is \"mint\" and Alan\\'s film really has a wonderful look to it. A great tribute to a wonderful film! The DVD\\'s resolution is even superior to the laserdisc quality! It\\'s just spectacular! Thank you Universal Home Video for the great quality control and transfer. Many thank\\'s for doing a superb job on this wonderful family film. Also many thank\\'s to you Alan for all your extreme kindness to me!!! It\\'s a real honor to know you!!! (Review Revised/Updated June 27, 2005)'"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_pos_df.iloc[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.8** <br> {points: 1}\n",
    "\n",
    "Using `best_model`, find the 5 movie reviews in the test set with the highest predicted probability of being negative (i.e., where the model is most confident that the review is negative).\n",
    "\n",
    "Save the reviews and the associated probability score in a dataframe named `most_neg_df`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "362d15028ab4eae0e106c0813abbd11d",
     "grade": false,
     "grade_id": "cell-30038642ed474e31",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>true_label</th>\n",
       "      <th>predicted_y</th>\n",
       "      <th>neg_label_prob</th>\n",
       "      <th>pos_label_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11992</th>\n",
       "      <td>Plankton, or Creatures from the Abyss as I'm p...</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.701106e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11677</th>\n",
       "      <td>The review on the main page admits that the mo...</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.155311e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11793</th>\n",
       "      <td>Komodo vs. Cobra starts as 'One Planet' enviro...</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.946306e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11814</th>\n",
       "      <td>WEll first and for most I'd just like to say t...</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.654804e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14056</th>\n",
       "      <td>I don't understand jokes. I do believe this is...</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.595324e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review true_label  \\\n",
       "11992  Plankton, or Creatures from the Abyss as I'm p...        neg   \n",
       "11677  The review on the main page admits that the mo...        neg   \n",
       "11793  Komodo vs. Cobra starts as 'One Planet' enviro...        neg   \n",
       "11814  WEll first and for most I'd just like to say t...        neg   \n",
       "14056  I don't understand jokes. I do believe this is...        neg   \n",
       "\n",
       "      predicted_y  neg_label_prob  pos_label_prob  \n",
       "11992         neg             1.0    3.701106e-09  \n",
       "11677         neg             1.0    4.155311e-09  \n",
       "11793         neg             1.0    8.946306e-09  \n",
       "11814         neg             1.0    1.654804e-08  \n",
       "14056         neg             1.0    3.595324e-08  "
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_neg_df = pd.DataFrame(results_df.sort_values(by= 'neg_label_prob', ascending = False).head(5))\n",
    "most_neg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dd6d7b1e1433b5653781d92ed528c5e5",
     "grade": true,
     "grade_id": "cell-20c66de412c3ec6a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_3_8(most_neg_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And what does a negative review read like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Plankton, or Creatures from the Abyss as I'm positive it's more commonly known as & filmed under as the title Creatures from the Abyss appears over a moving image & in the same font type as the rest of the credits, starts with five 20 something kids, Mike (Clay Rogers) his girlfriend Margaret (Sharon Twomey), sisters Julie (Ann Wolf) & Dorothy (Loren DePalm) & an annoying idiot named Bobby (Michael Bon) whom decide to all fit into a small rubber boat & head out to sea, don't ask why as I don't know. Oh & the complete idiot Bobby left the petrol behind & never thought to tell anyone so it comes as no great surprise that they end up stranded out at sea without any petrol for the motor & to make matters worse they become trapped in a thunder storm & discover a dead body floating in the water. Shortly after their luck seems to change when they come across a yacht & potential safety, in a flash everyone boards the yacht & begin to explore. First of all they find a scientific lab with various fish specimens & computer equipment, then down below they find fully furnished & luxurious cabins. They find a chemist (Deran Sarafian) who appears mad & can't talk. They eat fish from the fridge which makes Dorothy puke up green vomit, beetles & slugs. They learn that these fish are living fossil's 1000's of years old & have been contaminated by toxic waste dumped in the sea & that they fly, mutate, bite & are generally unpleasant to be around. I really can't be bothered to go on with this plot outline so I won't, here's what I think...<br /><br />This Italian production was produced & directed by Massimiliano Cerchi under the pseudonym Al Passeri (I'd hide under a different name if I made a film this bad too) & I think Plankton is quite simply one of the worst films ever, there are so many things wrong with this film it's difficult to know where to start. First the script by Richard Baumann is total crap, it makes no sense whatsoever & is so slow & dull it was torture for me to sit through. Why would five people just simply set sail for the middle of the ocean on a rubber dinghy barely big enough to fit them all in? What were they planning on doing exactly? Why do we often get point-of-view shots from these fish creatures but they seem to be totally invisible to the characters as they are never shown on screen even though they are right next to a character, & how do these fish get around the boat as there is no water for them to swim in? People's actions & reactions to things are all wrong, they constantly split up, they make bizarre decisions that simply don't make any sense in the situation they find themselves in & some of the dialogue is as awful as anything I've heard. I could go on all day about all the plot holes & ridiculous goings on but I'll run out of space if I do. The fish creatures themselves look awful, a mixture of rubbish rubber puppets & some really bad stop motion animation at the end, the scenes where they interact with the human cast also look terrible with some bad super imposition. I have heard a lot of comments saying that Plankton is gory, don't make me laugh! Forget it there is virtually no blood or gore in Plankton whatsoever, there are a couple of slimy scenes when Bobby transforms into a fish monster while having sex with Julie but it's pretty brief & he doesn't kill her, he just sort of drips slime on her, grows a couple of tentacles & a fish head comes out of his mouth. Later on Julie's vagina starts to drip some dark slime but that's it, we never get to actually see what happens to her or what the slime is. Dorothy has a fish creature come out of her back, off screen, & control her but again we never get to see what happens to her while Margaret commits suicide, a very brief shot of a plastic harpoon stuck to her forehead. Easily the grossest scene is when Dorothy pukes up that green stuff with what looks like beetles & slugs in it. That's it, only one person actually dies on screen & for the most part Plankton is quite tame & as exciting as watching paint dry & I nearly fell asleep it's so boring. I can't see how anybody can like this total crap, I just can't. The acting is awful, the dubbing is awful, the characters are awful & I hated all of them. Tecnically Plankton is predictably crap as well, with an estimated budget of only $250,000 all I can say is where did the money go? The sets are monotonous & dull with one lab & a few cabins, the special effect's are bottom of the barrel stuff including the most fake looking exploding boat ever, the cinematography is bland, the music sucks there is zero atmosphere or tension & as a whole Plankton, like it's name sake, is as low in the food chain as it could possibly be. I hate Plankton, it's awful in every single aspect of it's overlong 86 minute duration. Do yourself a favour & avoid this one at all costs unless your either a masochist or insomniac.\""
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_neg_df.iloc[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.9 - Optional** <br> {points: 0}\n",
    "This is an optional question!\n",
    "\n",
    "(You'll get 0 marks for this one but you may have fun doing it?!) \n",
    "\n",
    "Using `best_model`, find the 5 movie reviews in the test set with the most divided probability of being negative or positive (i.e., where the model is least confident in either review sentiment).\n",
    "\n",
    "Save the reviews and the associated probability score in a dataframe named `divided_revs_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5f1e658fb2a70bd0dcc73eca848e0c37",
     "grade": false,
     "grade_id": "cell-d4bcc26bae26cd03",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "results_df['prob_diff'] = results_df['pos_label_prob'].sub(results_df['neg_label_prob']).abs()\n",
    "divided_revs_df = pd.DataFrame(results_df.sort_values(by= 'prob_diff', ascending = False).head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0d455165c2d215f8f19e93882b08dd3d",
     "grade": true,
     "grade_id": "cell-b283c65b111507ce",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_3_9(divided_revs_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you attempted this question, uncomment the code below and read a review that the model was uncertain on classifying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plankton, or Creatures from the Abyss as I'm positive it's more commonly known as & filmed under as the title Creatures from the Abyss appears over a moving image & in the same font type as the rest of the credits, starts with five 20 something kids, Mike (Clay Rogers) his girlfriend Margaret (Sharon Twomey), sisters Julie (Ann Wolf) & Dorothy (Loren DePalm) & an annoying idiot named Bobby (Michael Bon) whom decide to all fit into a small rubber boat & head out to sea, don't ask why as I don't know. Oh & the complete idiot Bobby left the petrol behind & never thought to tell anyone so it comes as no great surprise that they end up stranded out at sea without any petrol for the motor & to make matters worse they become trapped in a thunder storm & discover a dead body floating in the water. Shortly after their luck seems to change when they come across a yacht & potential safety, in a flash everyone boards the yacht & begin to explore. First of all they find a scientific lab with various fish specimens & computer equipment, then down below they find fully furnished & luxurious cabins. They find a chemist (Deran Sarafian) who appears mad & can't talk. They eat fish from the fridge which makes Dorothy puke up green vomit, beetles & slugs. They learn that these fish are living fossil's 1000's of years old & have been contaminated by toxic waste dumped in the sea & that they fly, mutate, bite & are generally unpleasant to be around. I really can't be bothered to go on with this plot outline so I won't, here's what I think...<br /><br />This Italian production was produced & directed by Massimiliano Cerchi under the pseudonym Al Passeri (I'd hide under a different name if I made a film this bad too) & I think Plankton is quite simply one of the worst films ever, there are so many things wrong with this film it's difficult to know where to start. First the script by Richard Baumann is total crap, it makes no sense whatsoever & is so slow & dull it was torture for me to sit through. Why would five people just simply set sail for the middle of the ocean on a rubber dinghy barely big enough to fit them all in? What were they planning on doing exactly? Why do we often get point-of-view shots from these fish creatures but they seem to be totally invisible to the characters as they are never shown on screen even though they are right next to a character, & how do these fish get around the boat as there is no water for them to swim in? People's actions & reactions to things are all wrong, they constantly split up, they make bizarre decisions that simply don't make any sense in the situation they find themselves in & some of the dialogue is as awful as anything I've heard. I could go on all day about all the plot holes & ridiculous goings on but I'll run out of space if I do. The fish creatures themselves look awful, a mixture of rubbish rubber puppets & some really bad stop motion animation at the end, the scenes where they interact with the human cast also look terrible with some bad super imposition. I have heard a lot of comments saying that Plankton is gory, don't make me laugh! Forget it there is virtually no blood or gore in Plankton whatsoever, there are a couple of slimy scenes when Bobby transforms into a fish monster while having sex with Julie but it's pretty brief & he doesn't kill her, he just sort of drips slime on her, grows a couple of tentacles & a fish head comes out of his mouth. Later on Julie's vagina starts to drip some dark slime but that's it, we never get to actually see what happens to her or what the slime is. Dorothy has a fish creature come out of her back, off screen, & control her but again we never get to see what happens to her while Margaret commits suicide, a very brief shot of a plastic harpoon stuck to her forehead. Easily the grossest scene is when Dorothy pukes up that green stuff with what looks like beetles & slugs in it. That's it, only one person actually dies on screen & for the most part Plankton is quite tame & as exciting as watching paint dry & I nearly fell asleep it's so boring. I can't see how anybody can like this total crap, I just can't. The acting is awful, the dubbing is awful, the characters are awful & I hated all of them. Tecnically Plankton is predictably crap as well, with an estimated budget of only $250,000 all I can say is where did the money go? The sets are monotonous & dull with one lab & a few cabins, the special effect's are bottom of the barrel stuff including the most fake looking exploding boat ever, the cinematography is bland, the music sucks there is zero atmosphere or tension & as a whole Plankton, like it's name sake, is as low in the food chain as it could possibly be. I hate Plankton, it's awful in every single aspect of it's overlong 86 minute duration. Do yourself a favour & avoid this one at all costs unless your either a masochist or insomniac.\n"
     ]
    }
   ],
   "source": [
    "print(divided_revs_df.iloc[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.10 - Optional** <br> {points: 0}\n",
    "\n",
    "Here is another optional question!\n",
    "\n",
    "Examine a review from the test set where our `best_model` is making mistakes, i.e., where the true labels do not match the predicted labels. \n",
    "\n",
    "Save a (single) full row from `divided_revs_df` in an object named `wrong_review`. (We are expected a dataframe as the datatype for the autograder). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1017b2552127e609303dfc185646b2ed",
     "grade": false,
     "grade_id": "cell-2bd2d437b5dfa725",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "wrong_review = results_df.query('true_label != predicted_y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d9cf203b60431413312896457820f942",
     "grade": true,
     "grade_id": "cell-dee648fb1283ea86",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_3_10(wrong_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you attempted this question, uncomment the code below and read the review below. Does it make sense as to why the model got it wrong?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I get the feeling a lot of people liked this movie (not all people, but a lot of them) because they don\\'t want to admit they don\\'t understand it. People of middling intelligence, if you will, who pretend to be ever so avant garde and trendy who think Lynch is a genius.<br /><br />Lynch, to me, is like Tarantino. They\\'re both great, but neither one is the messiah as so many fanboys want to believe. No director can change the world, so chill out. And both make sucky flicks sometimes, it just happens. Everyone has a bad day. And clearly, since this movie was actually designed as a pilot first and then hack-jobbed into a feature film, it wasn\\'t made with all the passion and forethought one should put into a movie. Face it, much of the movie is gibbering unintelligibility which cannot be understood. We can all make up meanings, Lynch may have his own view, but none of that matters. It was strewn about the screen incoherently. Admittedly, the first portion had the semblance of an intentionally convoluted passingly interesting story, but then it falters.<br /><br />The cowboy, the mysterious organization of men with their phonecalls, the lawyers... come on. I can almost picture David Lynch yelling cut, forcing the crew to gather around him and explaining to them all \"Look how crazy and weird I am! Isn\\'t it great?? It\\'s so weird and crazy!\" Weird and crazy works if it\\'s a by-product of your style. However, it\\'s pretentious and tired when you go out of your way to do nothing but that. It\\'s like all those half assed Pulp Fiction throw backs that came out after Pulp Fiction. It\\'s just not cool.'"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_review.iloc[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attributions\n",
    "- The IMDB DataSet - [Kaggle](https://www.kaggle.com/utathya/imdb-review-dataset)\n",
    "\n",
    "- MDS DSCI 571 - Supervised Learning I - [MDS's GitHub website](https://github.com/UBC-MDS/DSCI_571_sup-learn-1) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before Submitting \n",
    "\n",
    "Before submitting your assignment please do the following:\n",
    "\n",
    "- Read through your solutions\n",
    "- **Restart your kernel and clear output and rerun your cells from top to bottom** \n",
    "- Makes sure that none of your code is broken \n",
    "- Verify that the tests from the questions you answered have obtained the output \"Success\"\n",
    "\n",
    "This is a simple way to make sure that you are submitting all the variables needed to mark the assignment. This method should help avoid losing marks due to changes in your environment.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
