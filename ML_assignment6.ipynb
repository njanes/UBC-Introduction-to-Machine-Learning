{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Machine Learning  \n",
    "\n",
    "## Assignment 6:  Preprocessing Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can't learn technical subjects without hands-on practice. The assignments are an important part of the course. To submit this assignment you will need to make sure that you save your Jupyter notebook. \n",
    "\n",
    "Below are the links of 2 videos that explain:\n",
    "\n",
    "1. [How to save your Jupyter notebook](https://youtu.be/0aoLgBoAUSA) and,       \n",
    "2. [How to answer a question in a Jupyter notebook assignment](https://youtu.be/7j0WKhI3W4s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment Learning Goals:\n",
    "\n",
    "By the end of the module, students are expected to:\n",
    "\n",
    "- Explain `handle_unknown=\"ignore\"` hyperparameter of `scikit-learn`'s `OneHotEncoder`.\n",
    "- Identify when it's appropriate to apply ordinal encoding vs one-hot encoding.\n",
    "- Explain strategies to deal with categorical variables with too many categories.\n",
    "- Explain why text data needs a different treatment than categorical variables.\n",
    "- Use `scikit-learn`'s `CountVectorizer` to encode text data.\n",
    "- Explain different hyperparameters of `CountVectorizer`.\n",
    "- Use `ColumnTransformer` to build all our transformations together into one object and use it with `scikit-learn` pipelines.\n",
    "\n",
    "This assignment covers [Module 6](https://ml-learn.mds.ubc.ca/en/module6) of the online course. You should complete this module before attempting this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any place you see `...`, you must fill in the function, variable, or data to complete the code. Substitute the `None` with your completed code and answers then proceed to run the cell!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that some of the questions in this assignment will have hidden tests. This means that no feedback will be given as to the correctness of your solution. It will be left up to you to decide if your answer is sufficiently correct. These questions are worth 2 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4b520ca500fe6daf2b0cff02d35c21b7",
     "grade": false,
     "grade_id": "cell-5e92ac69d9a55154",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataTransformerRegistry.enable('default')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import libraries needed for this lab\n",
    "from hashlib import sha1\n",
    "\n",
    "import altair as alt\n",
    "import graphviz\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import make_column_transformer \n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import (\n",
    "    FunctionTransformer,\n",
    "    Normalizer,\n",
    "    OneHotEncoder,\n",
    "    StandardScaler,\n",
    "    normalize,\n",
    "    scale)\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import test_assignment6 as t\n",
    "#alt.renderers.enable('mimetype')\n",
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introducing and Exploring the dataset <a name=\"1\"></a>\n",
    "<hr>\n",
    "\n",
    "\n",
    "In this lab you will be working with [the Olympics Games DataSet](https://www.kaggle.com/samruddhim/olympics-althlete-events-analysis).\n",
    "\n",
    "Our problem is to predict the medal type of each example. \n",
    " You can find more information on the dataset and features [here](https://www.kaggle.com/samruddhim/olympics-althlete-events-analysis).\n",
    "\n",
    "\n",
    "*Note that many popular datasets have sex as a feature where the possible values are male and female. This representation reflects how the data were collected and is not meant to imply that, for example, gender is binary.*\n",
    "\n",
    "\n",
    "The following starter code preprocesses the data to get rid of rows with `NaN` values in the target column `Medal`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "medal_df = pd.read_csv(\"data/athlete_events.csv\")\n",
    "medal_df = medal_df.dropna(subset=['Medal'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.1** <br> {points: 1}  \n",
    "\n",
    "In order to avoid violating the golden rule, before we do anything with the data, let's split it.\n",
    "\n",
    "Split the data into `train_df` (80%) and `test_df` (20%). \n",
    "\n",
    "Keep the target column (`Medal`) in the splits so that we can use it in EDA. \n",
    "\n",
    "Make sure to set `random_state=123` for grading purposes. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "398bda2225addd994c000cca833e4d4d",
     "grade": false,
     "grade_id": "cell-c9fddbf1159f2bc2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Team</th>\n",
       "      <th>NOC</th>\n",
       "      <th>Games</th>\n",
       "      <th>Year</th>\n",
       "      <th>Season</th>\n",
       "      <th>City</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Event</th>\n",
       "      <th>Medal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>221047</th>\n",
       "      <td>111063</td>\n",
       "      <td>Harbinder Singh Chimni</td>\n",
       "      <td>M</td>\n",
       "      <td>21.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>India</td>\n",
       "      <td>IND</td>\n",
       "      <td>1964 Summer</td>\n",
       "      <td>1964</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>Hockey</td>\n",
       "      <td>Hockey Men's Hockey</td>\n",
       "      <td>Gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222232</th>\n",
       "      <td>111670</td>\n",
       "      <td>Lars-Erik Skild</td>\n",
       "      <td>M</td>\n",
       "      <td>28.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>SWE</td>\n",
       "      <td>1980 Summer</td>\n",
       "      <td>1980</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Moskva</td>\n",
       "      <td>Wrestling</td>\n",
       "      <td>Wrestling Men's Lightweight, Greco-Roman</td>\n",
       "      <td>Bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122592</th>\n",
       "      <td>61968</td>\n",
       "      <td>Christa Khler (-Kinast)</td>\n",
       "      <td>F</td>\n",
       "      <td>24.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>East Germany</td>\n",
       "      <td>GDR</td>\n",
       "      <td>1976 Summer</td>\n",
       "      <td>1976</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Montreal</td>\n",
       "      <td>Diving</td>\n",
       "      <td>Diving Women's Springboard</td>\n",
       "      <td>Silver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14077</th>\n",
       "      <td>7597</td>\n",
       "      <td>Bao Yingying</td>\n",
       "      <td>F</td>\n",
       "      <td>24.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>China</td>\n",
       "      <td>CHN</td>\n",
       "      <td>2008 Summer</td>\n",
       "      <td>2008</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>Fencing</td>\n",
       "      <td>Fencing Women's Sabre, Team</td>\n",
       "      <td>Silver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222715</th>\n",
       "      <td>111877</td>\n",
       "      <td>Miroslav Slma</td>\n",
       "      <td>M</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Czechoslovakia</td>\n",
       "      <td>TCH</td>\n",
       "      <td>1948 Winter</td>\n",
       "      <td>1948</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Sankt Moritz</td>\n",
       "      <td>Ice Hockey</td>\n",
       "      <td>Ice Hockey Men's Ice Hockey</td>\n",
       "      <td>Silver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56592</th>\n",
       "      <td>28989</td>\n",
       "      <td>Milen Atanasov Dobrev</td>\n",
       "      <td>M</td>\n",
       "      <td>24.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>Bulgaria</td>\n",
       "      <td>BUL</td>\n",
       "      <td>2004 Summer</td>\n",
       "      <td>2004</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Athina</td>\n",
       "      <td>Weightlifting</td>\n",
       "      <td>Weightlifting Men's Middle-Heavyweight</td>\n",
       "      <td>Gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107633</th>\n",
       "      <td>54409</td>\n",
       "      <td>Larsen Alan Jensen</td>\n",
       "      <td>M</td>\n",
       "      <td>22.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>United States</td>\n",
       "      <td>USA</td>\n",
       "      <td>2008 Summer</td>\n",
       "      <td>2008</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>Swimming Men's 400 metres Freestyle</td>\n",
       "      <td>Bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122929</th>\n",
       "      <td>62140</td>\n",
       "      <td>Peter-Michael Kolbe</td>\n",
       "      <td>M</td>\n",
       "      <td>35.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>West Germany</td>\n",
       "      <td>FRG</td>\n",
       "      <td>1988 Summer</td>\n",
       "      <td>1988</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Seoul</td>\n",
       "      <td>Rowing</td>\n",
       "      <td>Rowing Men's Single Sculls</td>\n",
       "      <td>Silver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193716</th>\n",
       "      <td>97228</td>\n",
       "      <td>Oleg Alekseyevich Protopopov</td>\n",
       "      <td>M</td>\n",
       "      <td>35.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Soviet Union-1</td>\n",
       "      <td>URS</td>\n",
       "      <td>1968 Winter</td>\n",
       "      <td>1968</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Grenoble</td>\n",
       "      <td>Figure Skating</td>\n",
       "      <td>Figure Skating Mixed Pairs</td>\n",
       "      <td>Gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109718</th>\n",
       "      <td>55463</td>\n",
       "      <td>Steve Johnson</td>\n",
       "      <td>M</td>\n",
       "      <td>26.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>United States-2</td>\n",
       "      <td>USA</td>\n",
       "      <td>2016 Summer</td>\n",
       "      <td>2016</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Rio de Janeiro</td>\n",
       "      <td>Tennis</td>\n",
       "      <td>Tennis Men's Doubles</td>\n",
       "      <td>Bronze</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31826 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID                          Name Sex   Age  Height  Weight  \\\n",
       "221047  111063        Harbinder Singh Chimni   M  21.0   174.0    60.0   \n",
       "222232  111670               Lars-Erik Skild   M  28.0   170.0    70.0   \n",
       "122592   61968       Christa Khler (-Kinast)   F  24.0   162.0    56.0   \n",
       "14077     7597                  Bao Yingying   F  24.0   172.0    67.0   \n",
       "222715  111877                 Miroslav Slma   M  30.0     NaN     NaN   \n",
       "...        ...                           ...  ..   ...     ...     ...   \n",
       "56592    28989         Milen Atanasov Dobrev   M  24.0   177.0    94.0   \n",
       "107633   54409            Larsen Alan Jensen   M  22.0   185.0    88.0   \n",
       "122929   62140           Peter-Michael Kolbe   M  35.0   194.0    84.0   \n",
       "193716   97228  Oleg Alekseyevich Protopopov   M  35.0   175.0    71.0   \n",
       "109718   55463                 Steve Johnson   M  26.0   188.0    86.0   \n",
       "\n",
       "                   Team  NOC        Games  Year  Season            City  \\\n",
       "221047            India  IND  1964 Summer  1964  Summer           Tokyo   \n",
       "222232           Sweden  SWE  1980 Summer  1980  Summer          Moskva   \n",
       "122592     East Germany  GDR  1976 Summer  1976  Summer        Montreal   \n",
       "14077             China  CHN  2008 Summer  2008  Summer         Beijing   \n",
       "222715   Czechoslovakia  TCH  1948 Winter  1948  Winter    Sankt Moritz   \n",
       "...                 ...  ...          ...   ...     ...             ...   \n",
       "56592          Bulgaria  BUL  2004 Summer  2004  Summer          Athina   \n",
       "107633    United States  USA  2008 Summer  2008  Summer         Beijing   \n",
       "122929     West Germany  FRG  1988 Summer  1988  Summer           Seoul   \n",
       "193716   Soviet Union-1  URS  1968 Winter  1968  Winter        Grenoble   \n",
       "109718  United States-2  USA  2016 Summer  2016  Summer  Rio de Janeiro   \n",
       "\n",
       "                 Sport                                     Event   Medal  \n",
       "221047          Hockey                       Hockey Men's Hockey    Gold  \n",
       "222232       Wrestling  Wrestling Men's Lightweight, Greco-Roman  Bronze  \n",
       "122592          Diving                Diving Women's Springboard  Silver  \n",
       "14077          Fencing               Fencing Women's Sabre, Team  Silver  \n",
       "222715      Ice Hockey               Ice Hockey Men's Ice Hockey  Silver  \n",
       "...                ...                                       ...     ...  \n",
       "56592    Weightlifting    Weightlifting Men's Middle-Heavyweight    Gold  \n",
       "107633        Swimming       Swimming Men's 400 metres Freestyle  Bronze  \n",
       "122929          Rowing                Rowing Men's Single Sculls  Silver  \n",
       "193716  Figure Skating                Figure Skating Mixed Pairs    Gold  \n",
       "109718          Tennis                      Tennis Men's Doubles  Bronze  \n",
       "\n",
       "[31826 rows x 15 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(medal_df, train_size = 0.8, random_state = 123)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5ee0d61921ef4f124d18adc95f3aa3c5",
     "grade": true,
     "grade_id": "cell-a197fcf02a34fb83",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1_1(train_df,test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.2** <br> {points: 1}  \n",
    "\n",
    "How many examples are there in our training data? \n",
    "\n",
    "Save your answer in an object named `training_size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c7966d9aff51f0c62e34f9be90a9f6a1",
     "grade": false,
     "grade_id": "cell-bcb1ca7ea65e52b7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31826"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_size = len(train_df)\n",
    "training_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2320bc84859e3b0ec8d80c912fcd074b",
     "grade": true,
     "grade_id": "cell-5d56653aad604c93",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1_2(training_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.3** <br> {points: 3}  \n",
    "\n",
    "Let's examine our `train_df` a bit. \n",
    "\n",
    "What is the youngest and oldest age of an athlete that won a medal in the Olympics?\n",
    "\n",
    "Save the results in objects `youngest_age` and `oldest_age`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dda730e2a74a84a475f51eeab12f139e",
     "grade": false,
     "grade_id": "cell-a6c61e97a6a7d6d6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "describe_df = train_df.describe(include = 'all')\n",
    "youngest_age = describe_df.loc['min','Age']\n",
    "oldest_age = describe_df.loc['max','Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ca570ab4d4177f24cc83841fb2d99400",
     "grade": true,
     "grade_id": "cell-f7048261a24cea8a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# check that the variable exists\n",
    "assert 'oldest_age' in globals(\n",
    "), \"Please make sure that your solution is named 'oldest_age'\"\n",
    "\n",
    "# This test has been intentionally hidden. It will be up to you to decide if your solution\n",
    "# is sufficiently good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "adc6c0fe14b44ceb2856c616ad1a95f1",
     "grade": true,
     "grade_id": "cell-cc1717e5b43201b0",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1_3_2(youngest_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.4** <br> {points: 1}  \n",
    "\n",
    "Look at the column dtypes using `.info()`.\n",
    "\n",
    "How many non numeric **features** are there? \n",
    "\n",
    "Save the results in an object named `num_cat_feats`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2225da96b6ad5cc5ed5d1de70fd7ab9e",
     "grade": false,
     "grade_id": "cell-5c808e415e98b0be",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 31826 entries, 221047 to 109718\n",
      "Data columns (total 15 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   ID      31826 non-null  int64  \n",
      " 1   Name    31826 non-null  object \n",
      " 2   Sex     31826 non-null  object \n",
      " 3   Age     31228 non-null  float64\n",
      " 4   Height  24918 non-null  float64\n",
      " 5   Weight  24393 non-null  float64\n",
      " 6   Team    31826 non-null  object \n",
      " 7   NOC     31826 non-null  object \n",
      " 8   Games   31826 non-null  object \n",
      " 9   Year    31826 non-null  int64  \n",
      " 10  Season  31826 non-null  object \n",
      " 11  City    31826 non-null  object \n",
      " 12  Sport   31826 non-null  object \n",
      " 13  Event   31826 non-null  object \n",
      " 14  Medal   31826 non-null  object \n",
      "dtypes: float64(3), int64(2), object(10)\n",
      "memory usage: 4.9+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()\n",
    "num_cat_feats = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7899a4c872fa082fab5b050a99a73e74",
     "grade": true,
     "grade_id": "cell-0d096bba9ce22ae7",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1_4(num_cat_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.5** <br> {points: 3}  \n",
    "\n",
    "Let's take a look at some of the columns and the categories within them. \n",
    "\n",
    "Use `.describe` to answer the following questions. Save the describe dataframe in an object named `describe_df`.  \n",
    "\n",
    "a) Which categorical feature has the most unique values? Save this in an object named `most_unique`. \n",
    "\n",
    "b) How many binary columns are there? Save this in an object named `binary_cols`. \n",
    "\n",
    "c) How many categorical features have missing values? Save this number in an object named `missing_cat`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5545b1671e79653dadbcd69d87a76495",
     "grade": false,
     "grade_id": "cell-898755125a62cf22",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "describe_df\n",
    "\n",
    "most_unique = 'Name'\n",
    "binary_cols = 2\n",
    "missing_cat = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3ea69b979e81b9f60207f04212bbb327",
     "grade": true,
     "grade_id": "cell-27a94573d4090c6d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1_5_1(most_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ff333f4572634ebf68e8fdc58b14648",
     "grade": true,
     "grade_id": "cell-7e9bda74ff7409ff",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1_5_2(binary_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3008edc4096a9c503f033df717e4f785",
     "grade": true,
     "grade_id": "cell-8df6a68ea298ab95",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1_5_3(missing_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.6** <br> {points: 2}  \n",
    "\n",
    "Filter or groupby the `train_df` dataframe to answer the next question. \n",
    "\n",
    "Which `NOC` won the most medals? Save this in an object named `most_medals`. \n",
    "\n",
    "Which `NOC` won the most `Gold` medals? Save this in an object named `most_gold`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a0fb5f5a4c6831fdfcf3443e7289415e",
     "grade": false,
     "grade_id": "cell-bde68c09819e15f0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "medal_df = pd.DataFrame(train_df.groupby('NOC').apply(lambda x: x.value_counts('Medal')).sort_values(ascending = False))\n",
    "most_medals = 'USA'\n",
    "most_gold = 'USA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a87b2113bd4c9f848363f4e922995063",
     "grade": true,
     "grade_id": "cell-a9ee1795366bea98",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1_6_1(most_medals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c715b3d340b05e35edfe3c455b120f7b",
     "grade": true,
     "grade_id": "cell-9c95b1a4262f61d8",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1_6_2(most_gold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to separate feature vectors from the targets.\n",
    "\n",
    "We are only going to use the folowing columns:\n",
    "\n",
    "- `Sex`\n",
    "- `Age`\n",
    "- `Height`\n",
    "- `Weight`\n",
    "- `NOC`\n",
    "- `Year`\n",
    "- `Season`\n",
    "- `City`\n",
    "- `Sport`\n",
    "\n",
    "\n",
    "and using `Medal` as the target column. \n",
    "\n",
    "We've created  `X_train`, `y_train`, `X_test`, `y_test` for you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>NOC</th>\n",
       "      <th>Year</th>\n",
       "      <th>Season</th>\n",
       "      <th>City</th>\n",
       "      <th>Sport</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>221047</th>\n",
       "      <td>M</td>\n",
       "      <td>21.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>IND</td>\n",
       "      <td>1964</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>Hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222232</th>\n",
       "      <td>M</td>\n",
       "      <td>28.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>SWE</td>\n",
       "      <td>1980</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Moskva</td>\n",
       "      <td>Wrestling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122592</th>\n",
       "      <td>F</td>\n",
       "      <td>24.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>GDR</td>\n",
       "      <td>1976</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Montreal</td>\n",
       "      <td>Diving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14077</th>\n",
       "      <td>F</td>\n",
       "      <td>24.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>CHN</td>\n",
       "      <td>2008</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>Fencing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222715</th>\n",
       "      <td>M</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TCH</td>\n",
       "      <td>1948</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Sankt Moritz</td>\n",
       "      <td>Ice Hockey</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sex   Age  Height  Weight  NOC  Year  Season          City       Sport\n",
       "221047   M  21.0   174.0    60.0  IND  1964  Summer         Tokyo      Hockey\n",
       "222232   M  28.0   170.0    70.0  SWE  1980  Summer        Moskva   Wrestling\n",
       "122592   F  24.0   162.0    56.0  GDR  1976  Summer      Montreal      Diving\n",
       "14077    F  24.0   172.0    67.0  CHN  2008  Summer       Beijing     Fencing\n",
       "222715   M  30.0     NaN     NaN  TCH  1948  Winter  Sankt Moritz  Ice Hockey"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_df.drop(columns=['ID', 'Name', 'Team', 'Event','Medal', 'Games'])\n",
    "y_train = train_df['Medal']\n",
    "\n",
    "X_test = test_df.drop(columns=['ID', 'Name', 'Team', 'Event','Medal', 'Games'])\n",
    "y_test = test_df['Medal']\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing and building your pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.1** <br> {points: 4}  \n",
    "\n",
    "Before you can start preprocessing our data, you need to identify the binary, categorical, ordinal and numeric columns in your `X_train` and build lists of each feature type. \n",
    "\n",
    "\n",
    "Save the column names in lists named  `numeric_feats`, `binary_feats`, `categorical_feats` and `ordinal_feat`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>NOC</th>\n",
       "      <th>Year</th>\n",
       "      <th>Season</th>\n",
       "      <th>City</th>\n",
       "      <th>Sport</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>221047</th>\n",
       "      <td>M</td>\n",
       "      <td>21.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>IND</td>\n",
       "      <td>1964</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>Hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222232</th>\n",
       "      <td>M</td>\n",
       "      <td>28.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>SWE</td>\n",
       "      <td>1980</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Moskva</td>\n",
       "      <td>Wrestling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122592</th>\n",
       "      <td>F</td>\n",
       "      <td>24.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>GDR</td>\n",
       "      <td>1976</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Montreal</td>\n",
       "      <td>Diving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14077</th>\n",
       "      <td>F</td>\n",
       "      <td>24.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>CHN</td>\n",
       "      <td>2008</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>Fencing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222715</th>\n",
       "      <td>M</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TCH</td>\n",
       "      <td>1948</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Sankt Moritz</td>\n",
       "      <td>Ice Hockey</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sex   Age  Height  Weight  NOC  Year  Season          City       Sport\n",
       "221047   M  21.0   174.0    60.0  IND  1964  Summer         Tokyo      Hockey\n",
       "222232   M  28.0   170.0    70.0  SWE  1980  Summer        Moskva   Wrestling\n",
       "122592   F  24.0   162.0    56.0  GDR  1976  Summer      Montreal      Diving\n",
       "14077    F  24.0   172.0    67.0  CHN  2008  Summer       Beijing     Fencing\n",
       "222715   M  30.0     NaN     NaN  TCH  1948  Winter  Sankt Moritz  Ice Hockey"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "09ebcaabe87884abc686431c0b58444f",
     "grade": false,
     "grade_id": "cell-43b6a1d4d1641894",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "train_cols = list(X_train)\n",
    "numeric_feats = list(train_cols[i] for i in [1, 2, 3, 5])\n",
    "binary_feats = list(train_cols[i] for i in [0, 6])\n",
    "categorical_feats = list(train_cols[i] for i in [4, 7, 8])\n",
    "ordinal_feat = train_cols = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8c8cfa626fd296dcf63739fce9db3c68",
     "grade": true,
     "grade_id": "cell-a21f3a066962f23f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2_1_1(numeric_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9583fa5136fb2d0829bf005350e97c34",
     "grade": true,
     "grade_id": "cell-005c8032543d159e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2_1_2(binary_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a95a9495fb6699f046e179566f0a5195",
     "grade": true,
     "grade_id": "cell-b27a3dcda89adec6",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2_1_3(categorical_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2b92c0b09a2b55f5efd570151d559672",
     "grade": true,
     "grade_id": "cell-b43fdcc99ff0a5fa",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2_1_4(ordinal_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2** <br> {points: 1}  \n",
    "\n",
    "Ok let's start making our pipelines. Use `make_pipeline()` to make a pipeline for the numeric features called `numeric_transformer`. \n",
    "\n",
    "Use `SimpleImputation()` with `strategy=median`. For the second step make sure to use standardization with `StandardScaler()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "272038691a2b2d29665fa2b0c46dad20",
     "grade": false,
     "grade_id": "cell-83073da6c449aa14",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "numeric_transformer = make_pipeline(\n",
    "    SimpleImputer(strategy=\"median\"),\n",
    "    StandardScaler()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9536a6e75fbef1369554fac8024e876d",
     "grade": true,
     "grade_id": "cell-438e0937d545d5a5",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2_2(numeric_transformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3** <br> {points: 1}  \n",
    "\n",
    "Next, use `make_pipeline()` to make a pipeline for the categorical features called `categorical_transformer`. \n",
    "\n",
    "Use `SimpleImputation()` with `strategy=most_frequent`. \n",
    "\n",
    "Make sure to use the necessary one-hot encoding transformer with `dtype=int` and `handle_unknown=\"ignore\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f227940c6b8e034b8ae3435d96b5b871",
     "grade": false,
     "grade_id": "cell-6967c75a66f431f2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "categorical_transformer = make_pipeline(\n",
    "    SimpleImputer(strategy=\"most_frequent\"),\n",
    "    OneHotEncoder(dtype = int, handle_unknown = 'ignore')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0aa653f9f46004ff00e315d1a65b368e",
     "grade": true,
     "grade_id": "cell-53acdb809e9dda5a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2_3(categorical_transformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.4** <br> {points: 1}  \n",
    "  \n",
    "Use `make_pipeline()` to make a pipeline for the binary features call `binary_transformer`. \n",
    "\n",
    "Use `SimpleImputation()` with `strategy=most_frequent`. \n",
    "\n",
    "Make sure to use the necessary one-hot encoding transformer with `dtype=int`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e09717dce4dfb9f1eaebb06669831126",
     "grade": false,
     "grade_id": "cell-7dd0bd03ae4e6318",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "binary_transformer = make_pipeline(SimpleImputer(strategy = 'most_frequent'),\n",
    "                                  OneHotEncoder(dtype = int, drop = 'if_binary'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "74e4a7008494df664a2acc6369c6caa0",
     "grade": true,
     "grade_id": "cell-25e9e58ac84b4a2d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2_4(binary_transformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.5** <br> {points: 1}  \n",
    "\n",
    "\n",
    "Define a column transformer using [`make_column_transformer`](https://scikit-learn.org/stable/modules/generated/sklearn.compose.make_column_transformer.html) called `preprocessor` for the numerical, categorical, and remainding feature types.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c2b610cd853ef87e0d60f4b4b1b0f8d9",
     "grade": false,
     "grade_id": "cell-28dacb5959d6211d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "preprocessor = make_column_transformer(\n",
    "    (numeric_transformer, numeric_feats), \n",
    "    (categorical_transformer, categorical_feats),\n",
    "    (binary_transformer, binary_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7974551bfb35bb12919b7227c713f2a3",
     "grade": true,
     "grade_id": "cell-ff142c4bdd7dc427",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2_5(preprocessor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.1** <br> {points: 1}  \n",
    "\n",
    "It's important to build a dummy classifier to compare our model to. Make a `DummyClassifier` using `strategy=\"prior\"`. \n",
    "\n",
    "Carry out 5-fold cross validation on `X_train` and `y_train` using ` cross_validate()`. Don't forget to include the training score. \n",
    "\n",
    "Save the results in a dataframe named `dummy_scores`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "08eedaafc6264175397d726976be33cf",
     "grade": false,
     "grade_id": "cell-f05c1643222cdae8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.026392</td>\n",
       "      <td>0.006615</td>\n",
       "      <td>0.334433</td>\n",
       "      <td>0.334328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.026507</td>\n",
       "      <td>0.006675</td>\n",
       "      <td>0.334328</td>\n",
       "      <td>0.334355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.026132</td>\n",
       "      <td>0.006682</td>\n",
       "      <td>0.334328</td>\n",
       "      <td>0.334355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.026131</td>\n",
       "      <td>0.006717</td>\n",
       "      <td>0.334328</td>\n",
       "      <td>0.334355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.026275</td>\n",
       "      <td>0.006613</td>\n",
       "      <td>0.334328</td>\n",
       "      <td>0.334355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_score  train_score\n",
       "0  0.026392    0.006615    0.334433     0.334328\n",
       "1  0.026507    0.006675    0.334328     0.334355\n",
       "2  0.026132    0.006682    0.334328     0.334355\n",
       "3  0.026131    0.006717    0.334328     0.334355\n",
       "4  0.026275    0.006613    0.334328     0.334355"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_clf = DummyClassifier(strategy = 'prior')\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "dummy_scores = pd.DataFrame(cross_validate(dummy_clf, X_train, y_train, cv = 5, return_train_score=True))\n",
    "dummy_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a5d46cccd150ad0d0f98d55a7f455735",
     "grade": true,
     "grade_id": "cell-22c0fb890efc07ba",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_3_1(dummy_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.2** <br> {points: 1}  \n",
    "\n",
    "\n",
    "Define a main pipeline called `main_pipe` that transforms all the different features and uses a `RandomForestClassifier` model using `random_state=77` and setting the hyperparameter `n_estimators` to 10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d20b1a87f3f348f56e87b0369fef3079",
     "grade": false,
     "grade_id": "cell-0fa24b8f5c0ffebc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "main_pipe = make_pipeline(preprocessor, RandomForestClassifier(random_state = 77, n_estimators = 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "302502060294ab62b693527e287d07f2",
     "grade": true,
     "grade_id": "cell-afdeb02693cc4065",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_3_2(main_pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.3** <br> {points: 1}  \n",
    "\n",
    "Perform 5 fold cross-validation on `X_train` and `y_train` using the main pipeline `main_pipe`. Make sure to set `return_train_score=True` and save the result in a dataframe called `scores_df`. \n",
    "\n",
    "*Note: This could take 5 minutes. Remember how large our training data is.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c844bb3db03acae7cef3112de3409411",
     "grade": false,
     "grade_id": "cell-f59f426ce7ea817f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame(cross_validate(main_pipe, X_train, y_train, cv = 5, return_train_score = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "21275f2bbb9908b5972e811b9dbce015",
     "grade": true,
     "grade_id": "cell-135f717050ddcca3",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_3_3(scores_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.4** <br> {points: 2}\n",
    "\n",
    "What is the mean training and cross-validation scores? \n",
    "\n",
    "Save the mean training score in `mean_training_score` and the mean cross-validation score in the object named `cv_score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f3d44066eb7e87fc6142305a11fad604",
     "grade": false,
     "grade_id": "cell-bcfb2e25f0962f5a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9341261908105037 0.6159117898280807\n"
     ]
    }
   ],
   "source": [
    "mean_training_score = scores_df['train_score'].mean()\n",
    "cv_score = scores_df['test_score'].mean() \n",
    "print(mean_training_score, cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "39f779e4b20c0ff7faa19775c6e399b0",
     "grade": true,
     "grade_id": "cell-43da91b0a4ccb4f4",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# check that the variable exists\n",
    "assert 'cv_score' in globals(\n",
    "), \"Please make sure that your solution is named 'cv_score'\"\n",
    "\n",
    "assert 'mean_training_score' in globals(\n",
    "), \"Please make sure that your solution is named 'mean_training_score'\"\n",
    "# This test has been intentionally hidden. It will be up to you to decide if your solution\n",
    "# is sufficiently good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.5** <br> {points: 1}\n",
    "\n",
    "Is the model overfitting or underfitting? \n",
    "\n",
    "A) Overfitting\n",
    "\n",
    "B) Underfitting\n",
    "\n",
    "C) Neither\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between `\"\"`, assign the correct answer to an object called `answer3_05`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "de8868ef110890ed7e8a47154bb98ebc",
     "grade": false,
     "grade_id": "cell-81bbca69985958ef",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer3_05 = 'A'\n",
    "answer3_05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "08d301abc9b835102d9124b9222669dd",
     "grade": true,
     "grade_id": "cell-2a1d6ed12303efaf",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_3_5(answer3_05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.6** <br> {points: 1}\n",
    "\n",
    "Which model performed better?\n",
    "\n",
    "A) `RandomForestClassifier`\n",
    "\n",
    "B) `DummyClassifier`\n",
    "\n",
    "C) Neither\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between `\"\"`, assign the correct answer to an object called `answer3_06`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2632abe70454658e23a1bacc4e8594d2",
     "grade": false,
     "grade_id": "cell-4a863bf2d192b6ca",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer3_06 = 'A'\n",
    "answer3_06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "96c46088e16257c786f2241663f5c750",
     "grade": true,
     "grade_id": "cell-4ca0895e35271e81",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_3_6(answer3_06)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.7** <br> {points: 1}  \n",
    "Now that we have our pipelines and a model let's tune the hyperparameter `max_depth`. \n",
    "\n",
    "Sweep over the hyperparameters in `param_grid` using `RandomizedSearchCV` with a  `cv=5`, `n_iter=5` and setting `return_train_score=True`. Don't forget to set `random_state=77`.\n",
    "\n",
    "Save your grid search in an object named `depth_search`. \n",
    "\n",
    "You may also want to set `verbose=2` since it may take some time. \n",
    "\n",
    "Don't forget to fit `depth_search`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a4bf2fbb314f3c7524ba8c3f9c0cede5",
     "grade": false,
     "grade_id": "cell-b687a71a1bb9232c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV] END ..............randomforestclassifier__max_depth=141; total time=   3.7s\n",
      "[CV] END ..............randomforestclassifier__max_depth=141; total time=   3.6s\n",
      "[CV] END ..............randomforestclassifier__max_depth=141; total time=   3.7s\n",
      "[CV] END ..............randomforestclassifier__max_depth=141; total time=   3.6s\n",
      "[CV] END ..............randomforestclassifier__max_depth=141; total time=   3.6s\n",
      "[CV] END ...............randomforestclassifier__max_depth=61; total time=   3.3s\n",
      "[CV] END ...............randomforestclassifier__max_depth=61; total time=   2.9s\n",
      "[CV] END ...............randomforestclassifier__max_depth=61; total time=   3.0s\n",
      "[CV] END ...............randomforestclassifier__max_depth=61; total time=   2.8s\n",
      "[CV] END ...............randomforestclassifier__max_depth=61; total time=   2.9s\n",
      "[CV] END ...............randomforestclassifier__max_depth=21; total time=   0.7s\n",
      "[CV] END ...............randomforestclassifier__max_depth=21; total time=   0.7s\n",
      "[CV] END ...............randomforestclassifier__max_depth=21; total time=   0.7s\n",
      "[CV] END ...............randomforestclassifier__max_depth=21; total time=   0.7s\n",
      "[CV] END ...............randomforestclassifier__max_depth=21; total time=   0.7s\n",
      "[CV] END ...............randomforestclassifier__max_depth=91; total time=   3.6s\n",
      "[CV] END ...............randomforestclassifier__max_depth=91; total time=   3.5s\n",
      "[CV] END ...............randomforestclassifier__max_depth=91; total time=   3.6s\n",
      "[CV] END ...............randomforestclassifier__max_depth=91; total time=   4.0s\n",
      "[CV] END ...............randomforestclassifier__max_depth=91; total time=   3.6s\n",
      "[CV] END ...............randomforestclassifier__max_depth=31; total time=   1.3s\n",
      "[CV] END ...............randomforestclassifier__max_depth=31; total time=   1.2s\n",
      "[CV] END ...............randomforestclassifier__max_depth=31; total time=   1.2s\n",
      "[CV] END ...............randomforestclassifier__max_depth=31; total time=   1.2s\n",
      "[CV] END ...............randomforestclassifier__max_depth=31; total time=   1.3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('columntransformer',\n",
       "                                              ColumnTransformer(transformers=[('pipeline-1',\n",
       "                                                                               Pipeline(steps=[('simpleimputer',\n",
       "                                                                                                SimpleImputer(strategy='median')),\n",
       "                                                                                               ('standardscaler',\n",
       "                                                                                                StandardScaler())]),\n",
       "                                                                               ['Age',\n",
       "                                                                                'Height',\n",
       "                                                                                'Weight',\n",
       "                                                                                'Year']),\n",
       "                                                                              ('pipeline-2',\n",
       "                                                                               Pipeline(steps=[('simpleimputer',\n",
       "                                                                                                SimpleImputer(strategy='most_frequent')),\n",
       "                                                                                               ('oneh...\n",
       "                                                                                                SimpleImputer(strategy='most_frequent')),\n",
       "                                                                                               ('onehotencoder',\n",
       "                                                                                                OneHotEncoder(drop='if_binary',\n",
       "                                                                                                              dtype=<class 'int'>))]),\n",
       "                                                                               ['Sex',\n",
       "                                                                                'Season'])])),\n",
       "                                             ('randomforestclassifier',\n",
       "                                              RandomForestClassifier(n_estimators=10,\n",
       "                                                                     random_state=77))]),\n",
       "                   n_iter=5,\n",
       "                   param_distributions={'randomforestclassifier__max_depth': range(1, 151, 10)},\n",
       "                   random_state=77, return_train_score=True, verbose=2)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"randomforestclassifier__max_depth\": range(1,151,10)\n",
    "}\n",
    "\n",
    "depth_search = RandomizedSearchCV(main_pipe, param_grid, cv = 5, n_iter = 5, return_train_score = True, random_state = 77, verbose = 2)\n",
    "depth_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e1cce7f09596b674ae3cd135e1ec00b3",
     "grade": true,
     "grade_id": "cell-75006cd515e05a64",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_3_7(depth_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.8** <br> {points: 1}  \n",
    "\n",
    "Obtain the results for cross validation from grid search using `depth_search.cv_results_`.\n",
    "\n",
    "Select the columns:\n",
    "\n",
    "- `mean_test_score`\n",
    "- `param_randomforestclassifier__max_depth`\n",
    "- `mean_fit_time`\n",
    "- `rank_test_score`\n",
    "\n",
    "Sort your values in ascending order of `rank_test_score`. \n",
    "\n",
    "Make sure to save it as a dataframe and display it. Save this as an object named `grid_results`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eb9f2bdc7614d97f23f8eae7ca2eaa39",
     "grade": false,
     "grade_id": "cell-c73fc243949e9f49",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "cv_df = pd.DataFrame(depth_search.cv_results_)\n",
    "grid_results = cv_df.loc[:,['mean_test_score','param_randomforestclassifier__max_depth','mean_fit_time','rank_test_score']].sort_values('rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7207b66c68dcd2085093e88605374a2d",
     "grade": true,
     "grade_id": "cell-eadfb6c58d1ab663",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_3_8(grid_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.9** <br> {points: 1} \n",
    "\n",
    "What is the best hyperparameter value for `n_estimators`? Save it in an object named `best_depth`. \n",
    "\n",
    "What was the corresponding validation score for it? Save this in an object named `best_depth_score`. \n",
    "\n",
    "*Hint: `.best_params_`  and `.best_score_` are helpful here.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0bb6de3b832f053040f2a228d12bfbfa",
     "grade": false,
     "grade_id": "cell-edd98dcf457de3e5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "best_depth = depth_search.best_params_['randomforestclassifier__max_depth'] \n",
    "\n",
    "best_depth_score = depth_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "86e5757ef8f646c2df2998f3bcf53b5f",
     "grade": true,
     "grade_id": "cell-e67515c39ce2aa0a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_3_9(depth_search, best_depth, best_depth_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Evaluating on the test set <a name=\"5\"></a>\n",
    "<hr>\n",
    "\n",
    "Now that we have a best performing model, it's time to assess our model on the set aside test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.1** <br> {points: 2} \n",
    "\n",
    "What is the training score of the best scoring model? Save the result in an object named `train_score`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5c94c4eb0cf1d9acb5f5a28ec1407e5b",
     "grade": false,
     "grade_id": "cell-77ddb96a4f2f131c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9341261908105037"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_score = cv_df.loc[0,'mean_train_score']\n",
    "train_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "76bcee2fa3fb3bfdd24c52e39f0fc411",
     "grade": true,
     "grade_id": "cell-323ba99aab8bcb16",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert 'train_score' in globals(\n",
    "), \"Please make sure that your solution is named 'train_score'\"\n",
    "# This test has been intentionally hidden. It will be up to you to decide if your solution\n",
    "# is sufficiently good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.2** <br> {points: 1} \n",
    "\n",
    "\n",
    "What is the test score of the best model? \n",
    "\n",
    "Score the best model from `depth_search` on `X_test` and `y_test`. \n",
    "\n",
    "Save the result in an object named `test_score`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9e06a21d2b503d055b6d9195f8f91641",
     "grade": false,
     "grade_id": "cell-2d926c965be49673",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_score = main_pipe.fit(X_test, y_test).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cba3d96d5a10d10a484292721128f9c7",
     "grade": true,
     "grade_id": "cell-061c35980f6ba1ac",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_4_2(test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's develop our own SMS spam filtering system using Kaggle's [SMS Spam Collection Dataset](https://www.kaggle.com/uciml/sms-spam-collection-dataset) that was originally referenced from [The UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection). \n",
    "\n",
    "We will use `CountVectorizer` to encode text messages and `SVC` for classification. \n",
    "\n",
    "**Sorry for the offensive language in some text messages; it's the reality of such platforms 😔. If you are sensitive to such language try not to read the raw messages.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     target                                                sms\n",
       "0       ham  Go until jurong point, crazy.. Available only ...\n",
       "1       ham                      Ok lar... Joking wif u oni...\n",
       "2      spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3       ham  U dun say so early hor... U c already then say...\n",
       "4       ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...     ...                                                ...\n",
       "5567   spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568    ham              Will Ì_ b going to esplanade fr home?\n",
       "5569    ham  Pity, * was in mood for that. So...any other s...\n",
       "5570    ham  The guy did some bitching but I acted like i'd...\n",
       "5571    ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_df = pd.read_csv(\"data/spam.csv\", encoding=\"latin-1\")\n",
    "sms_df = sms_df.drop([\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis=1)\n",
    "sms_df = sms_df.rename(columns={\"v1\": \"target\", \"v2\": \"sms\"})\n",
    "sms_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.1** <br> {points: 1}  \n",
    "\n",
    "Split `sms_df` into train (80%) and test splits (20%) setting `random_state=123`. \n",
    "Name your objects `text_train_df` and `text_test_df`. \n",
    "Examine the first few rows of the train portion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4f1f9ca32408423c2ee953bea0370a90",
     "grade": false,
     "grade_id": "cell-9f7221d877a99905",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "text_train_df, text_test_df = train_test_split(sms_df, test_size = 0.2, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bc69c84147d9f25369b80f9b16c11565",
     "grade": true,
     "grade_id": "cell-145c736bdec68746",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_5_1(text_train_df, text_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.2** <br> {points: 1}  \n",
    "\n",
    "Split both `text_train_df` and `text_test_df` into the target and feature columns. Here,  `target` is the target column (`y`) and `sms` is the column in your `X`. \n",
    "    \n",
    "Name your objects `X_text_train`, `y_text_train` and  `X_text_test` `y_text_test`.\n",
    "\n",
    "*Hint: Make sure that you are using single brackets (a Pandas Series) for your target (y) objects. The tests will not pass unless your y variables are of type Pandas Series. This can be done by selecting the column target with single square brackets.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8a2d94e6a1ad2fae9f0456077b67cc39",
     "grade": false,
     "grade_id": "cell-cd7f8f3b4425a0fb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X_text_train = text_train_df['sms'].drop(columns = 'target')\n",
    "y_text_train = text_train_df['target']\n",
    "X_text_test = text_test_df['sms'].drop(columns = 'target')\n",
    "y_text_test = text_test_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "721b2993f04fe810592c650e9df415ca",
     "grade": true,
     "grade_id": "cell-d885629e054764a8",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_5_2(X_text_train, X_text_test, y_text_train, y_text_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.3** <br> {points: 2}  \n",
    "\n",
    "Note that in case of text data, the usual EDA is not applicable. In this exercise will carry out some simple EDA to get a sense of the data.  \n",
    "\n",
    "What's the label distribution in the target column (How many `ham` and how many `spam` values do you have in the column `target`) in the training set? \n",
    "\n",
    "Save the result in an object named `target_freq`.\n",
    "\n",
    "The autograder is expecting an answer as a pandas series. \n",
    "\n",
    "*Hint: There is function that we use quite often that will give us the frequency of each category in a column.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ce63218cef6f2f9cd8a64f52c3f06525",
     "grade": false,
     "grade_id": "cell-66e5b9b27ae415fd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "ham     3843\n",
       "spam     614\n",
       "dtype: int64"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_freq = text_train_df.groupby('target').size() \n",
    "target_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "49ab5ddb825de9bc44c30600339f603b",
     "grade": true,
     "grade_id": "cell-bb2c970a1a708333",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert 'target_freq' in globals(\n",
    "), \"Please make sure that your solution is named 'target_freq'\"\n",
    "# This test has been intentionally hidden. It will be up to you to decide if your solution\n",
    "# is sufficiently good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.4** <br> {points: 1} \n",
    "\n",
    "What's the average length in characters of text messages? Save the value to the nearest whole value in an object named `avg_text`. \n",
    "\n",
    "*Hint: `str.len()` may come in handy here.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "55bb231d7eaa1cdf86e0ef9f19e4b447",
     "grade": false,
     "grade_id": "cell-d514abe705701cec",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "avg_text = text_train_df['sms'].str.len().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5d56171c69472a1c021cc2dca97eddeb",
     "grade": true,
     "grade_id": "cell-b240e742af836b18",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_5_4(avg_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.5** <br> {points: 1} \n",
    "\n",
    "Would you classify `sms` column as a categorical column? Does it make sense to carry out one-hot encoding on this column?\n",
    "\n",
    "A) It is a categorical column and I would carry out one-hot encoding on this column.\n",
    "\n",
    "B) It is a categorical column and I would **NOT** carry out one-hot encoding on this column.\n",
    "\n",
    "C) It is a free text column and I would carry out one-hot encoding on this column.\n",
    "\n",
    "D) It is a free text column and I would **NOT** carry out one-hot encoding on this column.\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between `\"\"`, assign the correct answer to an object called `answer5_05`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "98c9e79c7daa1d99cf72d4a37c9f7df8",
     "grade": false,
     "grade_id": "cell-c01dfe36a4f467d5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer5_05 = 'D'\n",
    "answer5_05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1f0299d675dadb5df54a2a41e3f00217",
     "grade": true,
     "grade_id": "cell-dfe834250d6b09da",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_5_5(answer5_05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.6** <br> {points: 0}  \n",
    "Import `CountVectorizer` from the appropriate library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c3092dd413c4774951019a4c96b670c4",
     "grade": false,
     "grade_id": "cell-f333f108a2c75667",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "926a2aae765e5d0557b2c6e32f1c2597",
     "grade": true,
     "grade_id": "cell-66d0bef026c821bf",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_5_6()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.7** <br> {points: 1} \n",
    "\n",
    "Transform the training data using `CountVectorizer` with default parameters. Create an object named `vec`, fit it on `X_text_train` and `y_text_train` and transform `X_text_train`. \n",
    "\n",
    "Save the newly transformed `X_text_train` in an object named `transformed_X_train`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0e43d364099fec2b0be6547164b82e37",
     "grade": false,
     "grade_id": "cell-ca5eec2f0c737712",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "vec = CountVectorizer()\n",
    "transformed_X_train = vec.fit(X_text_train, y_text_train).transform(X_text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4e8853c96229fc943a795c67db7094af",
     "grade": true,
     "grade_id": "cell-73aed6b046404ae9",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_5_7(transformed_X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.8** <br> {points: 1} \n",
    "\n",
    "How many features have been created to represent each text message? \n",
    "\n",
    "Save the value in an object named `vocab_size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dee70563cfff2cdc6bb9cb119a46675e",
     "grade": false,
     "grade_id": "cell-e442238d313db760",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "vocab_size = len(vec.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f7cd86ef9f58ad7820447f080273c200",
     "grade": true,
     "grade_id": "cell-72c5da0c2ffb0d8f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_5_8(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.9** <br> {points: 2} \n",
    "\n",
    "What does each feature represent and each feature value represent? \n",
    "\n",
    "A) A word in the corpus with the value representing the number of times the word occurs in the given text message.\n",
    "\n",
    "B) A text message in the corpus with the value representing the distance from the closest text in the corpus.\n",
    "\n",
    "C) An example in the corpus with the value representing the length of the text message.\n",
    "\n",
    "D) A sentence in the corpus with the value representing the number of times the sentence occurs in the given text message.\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between `\"\"`, assign the correct answer to an object called `answer5_09`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ca41355d95f4971a8ec20811dc97101a",
     "grade": false,
     "grade_id": "cell-17fce569088b4dde",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A'"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer5_09 ='A'\n",
    "answer5_09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "486a0f328eae1776cbe2d02aa283d201",
     "grade": true,
     "grade_id": "cell-76d7d64f99f7bd0e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert 'answer5_09' in globals(\n",
    "), \"Please make sure that your solution is named 'answer5_09'\"\n",
    "# This test has been intentionally hidden. It will be up to you to decide if your solution\n",
    "# is sufficiently good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.10** <br> {points: 1} \n",
    "\n",
    "Build a pipeline named `dummy_pipe` for feature extraction using `CountVectorizer` with `binary=True` and `DummyClassifier` with strategy equal to `most_frequent`.\n",
    "\n",
    "Use `cross_validate()`setting `cv=5` with `dummy_pipe` and set `return_train_score=True` on `X_text_train` and `y_text_train` to obtain the train and test scores. \n",
    "\n",
    "Save this in a dataframe named `dummy_scores`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e555219e0e932efb5808d021f9295dc7",
     "grade": false,
     "grade_id": "cell-3f148854b5096bc9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "dummy_pipe = make_pipeline(CountVectorizer(binary = True), DummyClassifier(strategy = 'most_frequent'))\n",
    "dummy_pipe.fit(X_text_train, y_text_train)\n",
    "dummy_scores = pd.DataFrame(cross_validate(dummy_pipe, X_text_train, y_text_train, cv = 5, return_train_score = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b52996cb4e1d0aa6c3e1f4107e27f950",
     "grade": true,
     "grade_id": "cell-bb094f41a3d43e3d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_5_10(dummy_pipe, dummy_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.11** <br> {points: 1} \n",
    "\n",
    "What are the mean values of the columns in `dummy_scores`? Save this in an object named `dummy_scores_mean`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c7f2749888ecc9aa57192d5a66496d1d",
     "grade": false,
     "grade_id": "cell-519fd24a924c6812",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "dummy_scores_mean = dummy_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "27c67c818c4b3ca62e5e49741dfb23b4",
     "grade": true,
     "grade_id": "cell-d7b59c9f43453d49",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_5_11(dummy_scores_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.12** <br> {points: 1} \n",
    "\n",
    "Very often representing your free text feature values in a binary format works better in practice than the default one and so we are going with that. \n",
    "\n",
    "Now build a pipeline named `svc_pipe_binary` for feature extraction using `CountVectorizer` with `binary=True` and `SVC` with default hyperparameters. Make sure you are using `make_pipeline()` for this. \n",
    "\n",
    "Cross validate on `svc_pipe_binary` using `X_text_train` and `y_text_train` and setting `cv=5`  and `return_train_score=True`.  \n",
    "\n",
    "Save the results in a dataframe named `svc_scores`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "130e89cb2cb6bc51d25f7e41e1229d82",
     "grade": false,
     "grade_id": "cell-f8aa769efb4ddd07",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "svc_pipe_binary = make_pipeline(CountVectorizer(binary = True), SVC())\n",
    "svc_scores = pd.DataFrame(cross_validate(svc_pipe_binary, X_text_train, y_text_train, cv = 5, return_train_score = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a9ca7b28765e05acd77c9f325144b217",
     "grade": true,
     "grade_id": "cell-ee7740c1ebaa2d8b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_5_12(svc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.13** <br> {points: 1} \n",
    "\n",
    "What are the mean values of the columns in `svc_scores`? Save this in an object named `svc_scores_mean`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9213ccc7e17e8849ec4a4ab9e83563ee",
     "grade": false,
     "grade_id": "cell-1de70ee7cd990ad9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "svc_scores_mean = svc_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b1abd6ce33c3245feb8c027a37c9626a",
     "grade": true,
     "grade_id": "cell-3ee2f16c5eff385a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_5_13(svc_scores_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5.14** <br> {points: 1} \n",
    "\n",
    "Are you getting better results with `SVC` compared to `DummyClassifier`?\n",
    "\n",
    "A) I am getting better results with `SVC`.\n",
    "\n",
    "B) I am getting better results with `DummyClassifier`.\n",
    "\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between `\"\"`, assign the correct answer to an object called `answer5_14`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cf8bdeb49e72cbc85450b3d001fe096f",
     "grade": false,
     "grade_id": "cell-f870ead92831a546",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A'"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer5_14 = 'A'\n",
    "answer5_14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "afa296be35dcb623101b4c60219dbf22",
     "grade": true,
     "grade_id": "cell-b91c1c3189925f5e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_5_14(answer5_14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attributions\n",
    "- The Olympics Games DataSet - [Kaggle](https://www.kaggle.com/samruddhim/olympics-althlete-events-analysis)\n",
    "\n",
    "- The SMS Spam Collection Dataset - [Kaggle](https://www.kaggle.com/uciml/sms-spam-collection-dataset) and [The UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection)\n",
    "\n",
    "    *Almeida, T.A., GÃ³mez Hidalgo, J.M., Yamakami, A. Contributions to the Study of SMS Spam Filtering: New Collection and Results. Proceedings of the 2011 ACM Symposium on Document Engineering (DOCENG'11), Mountain View, CA, USA, 2011*\n",
    "\n",
    "\n",
    "- MDS DSCI 571 - Supervised Learning I - [MDS's GitHub website](https://github.com/UBC-MDS/DSCI_571_sup-learn-1) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before Submitting \n",
    "\n",
    "Before submitting your assignment please do the following:\n",
    "\n",
    "- Read through your solutions\n",
    "- **Restart your kernel and clear output and rerun your cells from top to bottom** \n",
    "- Makes sure that none of your code is broken \n",
    "- Verify that the tests from the questions you answered have obtained the output \"Success\"\n",
    "\n",
    "This is a simple way to make sure that you are submitting all the variables needed to mark the assignment. This method should help avoid losing marks due to changes in your environment.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
