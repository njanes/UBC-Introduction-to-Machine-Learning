{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Machine Learning  \n",
    "\n",
    "## Assignment 7: Assessment and Measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can't learn technical subjects without hands-on practice. The assignments are an important part of the course. To submit this assignment you will need to make sure that you save your Jupyter notebook. \n",
    "\n",
    "Below are the links of 2 videos that explain:\n",
    "\n",
    "1. [How to save your Jupyter notebook](https://youtu.be/0aoLgBoAUSA) and,       \n",
    "2. [How to answer a question in a Jupyter notebook assignment](https://youtu.be/7j0WKhI3W4s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment Learning Goals:\n",
    "\n",
    "By the end of the module, students are expected to:\n",
    "\n",
    "- Explain why accuracy is not always the best metric in ML.\n",
    "- Explain components of a confusion matrix.\n",
    "- Define precision, recall, and f1-score and use them to evaluate different classifiers.\n",
    "- Identify whether there is class imbalance and whether you need to deal with it.\n",
    "- Explain `class_weight` and use it to deal with data imbalance.\n",
    "- Appropriately select a scoring metric given a regression problem.\n",
    "- Interpret and communicate the meanings of different scoring metrics on regression problems. MSE, RMSE, $R^2$, MAPE.\n",
    "- Apply different scoring functions with `cross_validate` and `GridSearchCV` and `RandomizedSearchCV`.\n",
    "\n",
    "\n",
    "This assignment covers [Module 7](https://ml-learn.mds.ubc.ca/en/module7) of the online course. You should complete this module before attempting this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any place you see `...`, you must fill in the function, variable, or data to complete the code. Substitute the `None` with your completed code and answers then proceed to run the cell!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that some of the questions in this assignment will have hidden tests. This means that no feedback will be given as to the correctness of your solution. It will be left up to you to decide if your answer is sufficiently correct. These questions are worth 2 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataTransformerRegistry.enable('default')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import libraries needed for this lab\n",
    "from hashlib import sha1\n",
    "\n",
    "import altair as alt\n",
    "import graphviz\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import make_column_transformer \n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.preprocessing import (\n",
    "    FunctionTransformer,\n",
    "    Normalizer,\n",
    "    OneHotEncoder,\n",
    "    StandardScaler,\n",
    "    normalize,\n",
    "    scale)\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.svm import SVC, SVR\n",
    "\n",
    "import test_assignment7 as t\n",
    "#alt.renderers.enable('mimetype')\n",
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Precision, recall, and f1 score \"by hand\" (without `sklearn`)\n",
    "\n",
    "\n",
    "Consider the problem of predicting whether a patient has a disease or not. Below are confusion matrices of two machine learning models: Model A and Model B. \n",
    "\n",
    "##### Model A\n",
    "|    Actual/Predicted      | Predicted disease | Predicted no disease |\n",
    "| :------------- | -----------------------: | -----------------------: |\n",
    "| **Actual disease**       | 2 | 8 |\n",
    "| **Actual no disease**       | 0 | 100 |\n",
    "\n",
    "\n",
    "##### Model B\n",
    "|    Actual/Predicted      | Predicted disease | Predicted no disease |\n",
    "| :------------- | -----------------------: | -----------------------: |\n",
    "| **Actual disease**       | 6 | 4 |\n",
    "| **Actual no disease**       | 10 | 90 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.1** <br> {points: 1}  \n",
    "\n",
    "Precision, recall, and f1 score depend crucially upon which class is considered \"positive\", that is the thing you wish to find. In the example above, which class is likely to be the \"positive\" class?\n",
    "\n",
    "Save the label name in a string object named `answer_1_1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9eb12811100c161cf3c213fe35709f21",
     "grade": false,
     "grade_id": "cell-10bccd38560266fa",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Actual disease'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_1_1 = 'Actual disease'\n",
    "answer_1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "adbcee21c3dfdda7bdf609a0bba2836d",
     "grade": true,
     "grade_id": "cell-58c8cbee8ef77632",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1_1(answer_1_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.2** <br> {points: 3}  \n",
    "\n",
    "Calculate accuracies for Model A and Model B. \n",
    "\n",
    "Save the values of each calculations as a fraction in objects name `model_a_acc` and `model_b_acc` respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f758987de44065f042166873d2d03e4a",
     "grade": false,
     "grade_id": "cell-da59f7cfdbd13642",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9272727272727272 0.8727272727272727\n"
     ]
    }
   ],
   "source": [
    "model_a_acc = (2+100)/(2+8+100)\n",
    "model_b_acc = (6+90)/(6+4+10+90)\n",
    "print(model_a_acc, model_b_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5da7b795c782fad3ecd1b4a46e86a3f1",
     "grade": true,
     "grade_id": "cell-112a1f1642f468fa",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1_2_1(model_a_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5439fe795a81ef68b4669b3f249316dd",
     "grade": true,
     "grade_id": "cell-7adaec399eb35deb",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# check that the variable exists\n",
    "assert 'model_b_acc' in globals(\n",
    "), \"Please make sure that your solution is named 'model_b_acc'\"\n",
    "\n",
    "# This test has been intentionally hidden. It will be up to you to decide if your solution\n",
    "# is sufficiently good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.3** <br> {points: 1}  \n",
    "\n",
    "Which model would you pick simply based on the accuracy metric? \n",
    "\n",
    "Save either \"Model A\" or \"Model B\" in an object named `answer_1_3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9df5766cefde9a9e9fa02bb2c9228a74",
     "grade": false,
     "grade_id": "cell-88e8a579efb8b86f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer_1_3 = 'Model A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "695f0efead049219fb2dcfc351bdb71a",
     "grade": true,
     "grade_id": "cell-6d1051aef2f7edba",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1_3(answer_1_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.4** <br> {points: 3}  \n",
    "\n",
    "Calculate precision, recall, f1-score for **Model A** by designating the appropriate fraction to objects named `a_precision`, `a_recall` and `a_f1`. \n",
    "\n",
    "You can use the objects `a_precision` and `a_recall` to use in your `a_f1` calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "49c3b792195c18ca1862fac873a0ebbd",
     "grade": false,
     "grade_id": "cell-4f35b1710839f096",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_precision:  1.0 ;  a_recall:  0.2 ;  a_f1:  0.33333333333333337\n"
     ]
    }
   ],
   "source": [
    "TP_A = 2\n",
    "FP_A = 0\n",
    "TN_A = 100\n",
    "FN_A = 8\n",
    "\n",
    "a_precision = TP_A/(TP_A+FP_A)\n",
    "a_recall = TP_A/(TP_A+FN_A)\n",
    "a_f1 = 2*((a_precision*a_recall)/(a_precision + a_recall))\n",
    "\n",
    "print('a_precision: ', a_precision, '; ',\n",
    "      'a_recall: ', a_recall, '; ', \n",
    "      'a_f1: ', a_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eb4920f56cf39a031adf747b2edb144d",
     "grade": true,
     "grade_id": "cell-ebc2c04c38d967f8",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1_4_1(a_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e4a6fd12459d024e700bac427d0588bd",
     "grade": true,
     "grade_id": "cell-e6873091826ecbfe",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1_4_2(a_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bf10040bc55dcb1d892339cacec1f878",
     "grade": true,
     "grade_id": "cell-22acb42332686294",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1_4_3(a_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.5** <br> {points: 3}  \n",
    "\n",
    "Calculate precision, recall, f1-score for **Model B** by designating the appropriate fraction to objects named `b_precision`, `b_recall` and `b_f1`. \n",
    "\n",
    "You can use the objects `b_precision` and `b_recall` to use in your `b_f1` calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "86355ab435db5480187ba8edc86054b0",
     "grade": false,
     "grade_id": "cell-1464d82d29d554be",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b_precision:  0.375 ;  b_recall:  0.6 ;  b_f1:  0.4615384615384615\n"
     ]
    }
   ],
   "source": [
    "TP_B = 6\n",
    "FP_B = 10\n",
    "TN_B = 90\n",
    "FN_B = 4\n",
    "\n",
    "b_precision = TP_B/(TP_B+FP_B)\n",
    "b_recall = TP_B/(TP_B+FN_B)\n",
    "b_f1 = 2*((b_precision*b_recall)/(b_precision + b_recall))\n",
    "\n",
    "print('b_precision: ', b_precision, '; ',\n",
    "      'b_recall: ', b_recall, '; ', \n",
    "      'b_f1: ', b_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6a8846c7780c15cd0ba596718f2c0ce1",
     "grade": true,
     "grade_id": "cell-c41145a09c7bfc8b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1_5_1(b_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "20a1bbdd0ae50247b9003023be15fa83",
     "grade": true,
     "grade_id": "cell-6564d4b3d12c0f51",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1_5_2(b_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "61278e395335b95ca3af119b70169b1b",
     "grade": true,
     "grade_id": "cell-a97d0ee2aa39b97c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1_5_3(b_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.6** <br> {points: 1}  \n",
    "\n",
    "Which metric is more informative in this case?\n",
    "\n",
    "i) Accuracy\n",
    "\n",
    "ii) Precision\n",
    "\n",
    "iii) Recall\n",
    "\n",
    "iv) f1\n",
    "\n",
    "\n",
    "\n",
    "Select all that apply and add them into a list named `answer_1_6`. \n",
    "For example if statement i and iv are both true, your solution will look like this: \n",
    "\n",
    "```\n",
    "answer_1_6 = [\"i\", \"iv\"] \n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fb0b62c5b0974c0126f91063234f13bc",
     "grade": false,
     "grade_id": "cell-94a5d47d39c26a6e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer_1_6 = ['iii', 'iv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "02f02a17203cdb6875af1c4ba573b101",
     "grade": true,
     "grade_id": "cell-40689573c4b45ba7",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1_6(answer_1_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.7** <br> {points: 1}  \n",
    "\n",
    "Which model would you pick based on this information? \n",
    "\n",
    "Save either \"Model A\" or \"Model B\" in an object named `answer_1_7`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f0e1d55a4feedcd1b09a39cbc1b56428",
     "grade": false,
     "grade_id": "cell-4dd94c25673682b2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer_1_7 = 'Model B'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c67be0c0ff2a40c752c9078d6ee1ac1d",
     "grade": true,
     "grade_id": "cell-3b1fd3696243d2e6",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_1_7(answer_1_7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Classification evaluation metrics using `sklearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, when a dataset is imbalanced, accuracy does not provide the whole story. In the module material, we looked at a credit card fraud dataset which is a classic example of an imbalanced dataset. Another example is customer churn datasets. For the next questions, you will be using a [bank customer churn dataset](https://www.kaggle.com/shubh0799/churn-modelling) from Kaggle. In this question, we will be concentrating on the target label `Exited`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3144</th>\n",
       "      <td>15638003</td>\n",
       "      <td>648</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>81370.07</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>181534.04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9939</th>\n",
       "      <td>15808971</td>\n",
       "      <td>693</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>57</td>\n",
       "      <td>9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>135502.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7925</th>\n",
       "      <td>15800482</td>\n",
       "      <td>586</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>33</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>168261.40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>15746726</td>\n",
       "      <td>438</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>78398.69</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>44937.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9415</th>\n",
       "      <td>15750407</td>\n",
       "      <td>768</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>129264.05</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19150.14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CustomerId  CreditScore Geography  Gender  Age  Tenure    Balance  \\\n",
       "3144    15638003          648     Spain    Male   55       1   81370.07   \n",
       "9939    15808971          693     Spain  Female   57       9       0.00   \n",
       "7925    15800482          586     Spain  Female   33       7       0.00   \n",
       "309     15746726          438   Germany    Male   31       8   78398.69   \n",
       "9415    15750407          768   Germany  Female   43       2  129264.05   \n",
       "\n",
       "      NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "3144              1          0               1        181534.04       0  \n",
       "9939              2          1               1        135502.77       0  \n",
       "7925              2          1               1        168261.40       0  \n",
       "309               1          1               0         44937.01       0  \n",
       "9415              2          0               0         19150.14       0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_df = pd.read_csv(\"data/churn.csv\")\n",
    "train_df, test_df = train_test_split(churn_df, test_size=0.3, random_state=123)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.1** <br> {points: 1}  \n",
    "\n",
    "What is the distribution of target values (`Exited`) in the train split? Your answer should be of type Pandas Series and saved in an object named `class_dist`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "44665c095202fa383686378d2c4c1883",
     "grade": false,
     "grade_id": "cell-8fee174efb95046b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class_dist = train_df.groupby('Exited').size() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fa37bbafe6269aa3afd61bfa4b599abb",
     "grade": true,
     "grade_id": "cell-9693a3487c29667f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2_1(class_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2** <br> {points: 1}  \n",
    "\n",
    "Let's now separate our feature vectors from the target.\n",
    "\n",
    "Use all the columns except for `Exited` as your `X` and the `Exited` column as your target `y`. \n",
    "\n",
    "You will need to split both `train_df` and `test_df`. \n",
    "\n",
    "Save the results in objects named `X_train`, `y_train`, `X_test` and `y_test`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d7222433fd61a1eb03f0ef20132bb45f",
     "grade": false,
     "grade_id": "cell-912921e7e74800fb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3144</th>\n",
       "      <td>15638003</td>\n",
       "      <td>648</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>81370.07</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>181534.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9939</th>\n",
       "      <td>15808971</td>\n",
       "      <td>693</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>57</td>\n",
       "      <td>9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>135502.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7925</th>\n",
       "      <td>15800482</td>\n",
       "      <td>586</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>33</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>168261.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>15746726</td>\n",
       "      <td>438</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>78398.69</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>44937.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9415</th>\n",
       "      <td>15750407</td>\n",
       "      <td>768</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>129264.05</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19150.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CustomerId  CreditScore Geography  Gender  Age  Tenure    Balance  \\\n",
       "3144    15638003          648     Spain    Male   55       1   81370.07   \n",
       "9939    15808971          693     Spain  Female   57       9       0.00   \n",
       "7925    15800482          586     Spain  Female   33       7       0.00   \n",
       "309     15746726          438   Germany    Male   31       8   78398.69   \n",
       "9415    15750407          768   Germany  Female   43       2  129264.05   \n",
       "\n",
       "      NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  \n",
       "3144              1          0               1        181534.04  \n",
       "9939              2          1               1        135502.77  \n",
       "7925              2          1               1        168261.40  \n",
       "309               1          1               0         44937.01  \n",
       "9415              2          0               0         19150.14  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_df.drop(columns = 'Exited')\n",
    "y_train = train_df['Exited']\n",
    "X_test = test_df.drop(columns = 'Exited')\n",
    "y_test = test_df['Exited']\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6568c622b7399949d5a1464f03764be0",
     "grade": true,
     "grade_id": "cell-f7c38b0ae6f70af2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2_2(X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3** <br> {points: 1} \n",
    "\n",
    "Carry out cross-validation with `DummyClassifier` using the `stratified` strategy. Pass the following `scoring` metrics to `cross_validate`. \n",
    "- accuracy\n",
    "- f1\n",
    "- recall\n",
    "- precision\n",
    "\n",
    "Make sure you use  `return_train_score=True` and 5-fold cross-validation.\n",
    "\n",
    "Save your results in a dataframe named `dummy_scores`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7b8dce2b95c43593a7a04bf25b0be9b9",
     "grade": false,
     "grade_id": "cell-c6682256ddbc4a46",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002575</td>\n",
       "      <td>0.005969</td>\n",
       "      <td>0.677143</td>\n",
       "      <td>0.677679</td>\n",
       "      <td>0.228669</td>\n",
       "      <td>0.215558</td>\n",
       "      <td>0.234266</td>\n",
       "      <td>0.216405</td>\n",
       "      <td>0.223333</td>\n",
       "      <td>0.214719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.005603</td>\n",
       "      <td>0.665000</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.181501</td>\n",
       "      <td>0.203850</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.203316</td>\n",
       "      <td>0.181185</td>\n",
       "      <td>0.204386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001791</td>\n",
       "      <td>0.043717</td>\n",
       "      <td>0.662143</td>\n",
       "      <td>0.672857</td>\n",
       "      <td>0.188679</td>\n",
       "      <td>0.202091</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.202443</td>\n",
       "      <td>0.185185</td>\n",
       "      <td>0.201739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001822</td>\n",
       "      <td>0.005492</td>\n",
       "      <td>0.682857</td>\n",
       "      <td>0.673929</td>\n",
       "      <td>0.201439</td>\n",
       "      <td>0.208153</td>\n",
       "      <td>0.195122</td>\n",
       "      <td>0.209607</td>\n",
       "      <td>0.208178</td>\n",
       "      <td>0.206718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001648</td>\n",
       "      <td>0.005428</td>\n",
       "      <td>0.667857</td>\n",
       "      <td>0.669107</td>\n",
       "      <td>0.194107</td>\n",
       "      <td>0.202325</td>\n",
       "      <td>0.195122</td>\n",
       "      <td>0.205240</td>\n",
       "      <td>0.193103</td>\n",
       "      <td>0.199491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fit_time  score_time  test_accuracy  train_accuracy   test_f1  train_f1  \\\n",
       "0  0.002575    0.005969       0.677143        0.677679  0.228669  0.215558   \n",
       "1  0.001770    0.005603       0.665000        0.675000  0.181501  0.203850   \n",
       "2  0.001791    0.043717       0.662143        0.672857  0.188679  0.202091   \n",
       "3  0.001822    0.005492       0.682857        0.673929  0.201439  0.208153   \n",
       "4  0.001648    0.005428       0.667857        0.669107  0.194107  0.202325   \n",
       "\n",
       "   test_recall  train_recall  test_precision  train_precision  \n",
       "0     0.234266      0.216405        0.223333         0.214719  \n",
       "1     0.181818      0.203316        0.181185         0.204386  \n",
       "2     0.192308      0.202443        0.185185         0.201739  \n",
       "3     0.195122      0.209607        0.208178         0.206718  \n",
       "4     0.195122      0.205240        0.193103         0.199491  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_clf = DummyClassifier(strategy = 'stratified')\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "scoring = ['accuracy', 'f1', 'recall', 'precision']\n",
    "dummy_scores = pd.DataFrame(cross_validate(dummy_clf, X_train, y_train, scoring = scoring, return_train_score = True))\n",
    "dummy_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "33b2620699332d7a72bfbbf4d5090a9c",
     "grade": true,
     "grade_id": "cell-f74782b5290c5565",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2_3(dummy_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.4** <br> {points: 1} \n",
    "\n",
    "What is the mean of each column in `dummy_scores`?\n",
    "\n",
    "\n",
    "Save your result in an object named `dummy_mean`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2d74ea25a828ef05c7e99569d8315da4",
     "grade": false,
     "grade_id": "cell-99de59fe13557284",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "dummy_mean = dummy_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ad18f1577384e05167832bde2092cf42",
     "grade": true,
     "grade_id": "cell-57af51df99cb0bdf",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2_4(dummy_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.5** <br> {points: 5}  \n",
    "\n",
    "Using either `.describe(include=\"all\")`, `.info()` or looking at the data, split it into 4 types of features; numeric, categorical, binary and `drop_features`. \n",
    "\n",
    "- Add the labels of the numeric column(s) (as type string) to a list name `numeric_features`.\n",
    "- Add the labels of the categorical column(s) (as type string) to a list name `categorical_features`.\n",
    "- Add the labels of the binary column(s) (as type string) to a list name `binary_features`.\n",
    "- Add the labels of the column that should be excluded from the model fitting to a list named `drop_features`. _(Hint: which of the columns is a unique identifier for the examples?)_\n",
    "\n",
    "Identify different feature types (e.g., numeric, categorical, binary, drop features).\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CustomerId',\n",
       " 'CreditScore',\n",
       " 'Geography',\n",
       " 'Gender',\n",
       " 'Age',\n",
       " 'Tenure',\n",
       " 'Balance',\n",
       " 'NumOfProducts',\n",
       " 'HasCrCard',\n",
       " 'IsActiveMember',\n",
       " 'EstimatedSalary',\n",
       " 'Exited']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(churn_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "276c576ccc6e6b210cd4ba1ae0cc7360",
     "grade": false,
     "grade_id": "cell-66dbf242bf1a9faa",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "numeric_features = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary']\n",
    "categorical_features = ['Geography']\n",
    "drop_features = ['CustomerId']\n",
    "binary_features = ['Gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3e01d54db20b8c570ddc3c2e4bf8c4ef",
     "grade": true,
     "grade_id": "cell-b422078fdd00a9a8",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2_5_1(numeric_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6593b949763776cecf0d519875726fbb",
     "grade": true,
     "grade_id": "cell-fd94cbdf40c54387",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# check that the variable exists\n",
    "assert 'categorical_features' in globals(\n",
    "), \"Please make sure that your solution is named 'categorical_features'\"\n",
    "\n",
    "# This test has been intentionally hidden. It will be up to you to decide if your solution\n",
    "# is sufficiently good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b319e1c5c2143f1c1facad9f2661aa27",
     "grade": true,
     "grade_id": "cell-9260945a70a8df44",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2_5_3(drop_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ba41741e8cd540f315c47d432d8e1294",
     "grade": true,
     "grade_id": "cell-8a7d80a0f3f69e0b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2_5_4(binary_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have no null values we can skip the individual pipelines and make our column transforming with just a single transformation. \n",
    "\n",
    "Because everyone needs a little help once in a while, we are going to do this part for you! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = make_column_transformer(\n",
    "    (\"drop\", drop_features),\n",
    "    (StandardScaler(), numeric_features),\n",
    "    (OneHotEncoder(handle_unknown=\"ignore\"), categorical_features),\n",
    "    (OneHotEncoder(handle_unknown=\"error\", drop=\"if_binary\"), binary_features)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.6** <br> {points: 2}  \n",
    "\n",
    "In this question, you will be using the [`RandomForestClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) which you haven't studied yet but did see in assignment 3.  You should feel comfortable using models with our usual ML workflow even if you haven't seen them before. \n",
    "\n",
    "\n",
    "Build a pipeline named `unbalanced_pipe` that first preprocesses `preprocessor` and then builds a  `RandomForestClassifier` using a random_state of 77. \n",
    "\n",
    "Carry out cross-validation on `unbalanced_pipe` and the training set using the `cross_validate` function and the following evaluation metrics:\n",
    "- `accuracy`\n",
    "- `precision`\n",
    "- `recall`\n",
    "- `f1`\n",
    "\n",
    "Note that you can pass multiple [scoring metrics](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter) as a list or a dict to the `scoring` parameter. \n",
    "\n",
    "Save the results of the cross-validation in a dataframe named`rf_unbalanced_scores`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c9e544e4a429e0c47241b64eb1eb8d2e",
     "grade": false,
     "grade_id": "cell-0de662581b33ae12",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "unbalanced_pipe = make_pipeline(preprocessor, RandomForestClassifier(random_state = 77))\n",
    "unbalanced_pipe.fit(X_train, y_train)\n",
    "scoring = ['accuracy','f1','recall','precision']\n",
    "cv = cross_validate(unbalanced_pipe, X_train, y_train, cv = 5, scoring = scoring, return_train_score = True)\n",
    "rf_unbalanced_scores = pd.DataFrame(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cf19a4f79b7fb0b22960cae2227b3a22",
     "grade": true,
     "grade_id": "cell-e578cb24650f0946",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2_6(rf_unbalanced_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.7** <br> {points: 1} \n",
    "\n",
    "What is the mean of each column in `rf_unbalanced_scores`?\n",
    "\n",
    "\n",
    "Save your result in an object named `rf_unbalanced_mean`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3689cb896183d89fb73b66b95b686e08",
     "grade": false,
     "grade_id": "cell-22fba680c83299d9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time           0.838242\n",
       "score_time         0.052098\n",
       "test_accuracy      0.857143\n",
       "train_accuracy     1.000000\n",
       "test_f1            0.559844\n",
       "train_f1           1.000000\n",
       "test_recall        0.444811\n",
       "train_recall       1.000000\n",
       "test_precision     0.758343\n",
       "train_precision    1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_unbalanced_mean = rf_unbalanced_scores.mean()\n",
    "rf_unbalanced_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "686881db3c233c199a755d522cff5785",
     "grade": true,
     "grade_id": "cell-472ac701d5761924",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2_7(rf_unbalanced_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.8** <br> {points: 2}  \n",
    "\n",
    "Repeat question 6 above but this time set `class_weight=\"balanced\"` in the `RandomForestClassifier`. \n",
    "Save the new pipeline in an object named `balanced_pipe`. Don't forget to use `random_state=77`for the classifier. \n",
    "\n",
    "Carry out cross-validation on `balanced_pipe` but this time save the scores in a dataframe named `rf_balanced_scores`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "202526d1904a72b94b36106669929ff9",
     "grade": false,
     "grade_id": "cell-1c4687b4a9a6aac8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "unbalanced_pipe = make_pipeline(preprocessor, RandomForestClassifier(random_state = 77, class_weight = 'balanced'))\n",
    "unbalanced_pipe.fit(X_train, y_train)\n",
    "scoring = ['accuracy','f1','recall','precision']\n",
    "cv = cross_validate(unbalanced_pipe, X_train, y_train, cv = 5, scoring = scoring, return_train_score = True)\n",
    "rf_balanced_scores = pd.DataFrame(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7a7620a4c80f3634f445ffa7ae772dcd",
     "grade": true,
     "grade_id": "cell-49f5395fd9aa9edd",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2_8(rf_balanced_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.9** <br> {points: 1} \n",
    "\n",
    "What is the mean of each column in `rf_balanced_scores`?\n",
    "\n",
    "\n",
    "Save your result in an object named `rf_balanced_mean`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0fd2ed2b7e126bb421670acc51b7e679",
     "grade": false,
     "grade_id": "cell-1d3c898d4c72428c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_time           1.038541\n",
       "score_time         0.072518\n",
       "test_accuracy      0.857714\n",
       "train_accuracy     1.000000\n",
       "test_f1            0.550549\n",
       "train_f1           1.000000\n",
       "test_recall        0.428038\n",
       "train_recall       1.000000\n",
       "test_precision     0.775329\n",
       "train_precision    1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_balanced_mean = rf_balanced_scores.mean()\n",
    "rf_balanced_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f3cf89f57851f482b3300f32b64441b5",
     "grade": true,
     "grade_id": "cell-f57fbaf001a3bd23",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2_9(rf_balanced_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.10** <br> {points: 1} \n",
    "\n",
    "Look at your results above. Which of the following statements are true? \n",
    "\n",
    "i) Both random forest models have better mean validation accuracy performance than the dummy classifier.\n",
    "\n",
    "ii) The balanced class random forest model has a better mean validation recall score than the unbalanced random forest model. \n",
    "\n",
    "iii) The balanced class random forest model has a better mean validation precision score than the unbalanced random forest model.  \n",
    "\n",
    "iv) Mean validation precision and recall scores only increased in the balanced class random forest model.\n",
    "\n",
    "v) Both random forest models show higher validation precision scores than validation recall scores. \n",
    "\n",
    "\n",
    "Select all that apply and add them into a list named `answer_2_10`. \n",
    "For example if statement i and iv are both true, your solution will look like this: \n",
    "\n",
    "```\n",
    "answer_2_10 = [\"i\", \"iv\"] \n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0f28fc9c7029911084e74b483324d565",
     "grade": false,
     "grade_id": "cell-6de147c823c76215",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer_2_10 = ['i','iii','v']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9277f4f016fc9760497d21a42eee8b91",
     "grade": true,
     "grade_id": "cell-fd3c4b417ac834cf",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2_10(answer_2_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.11** <br> {points: 1} \n",
    "\n",
    "For this next question, we have given you the majority of the code to hyperparameter tune the balanced `RandomForestClassifier`. \n",
    "\n",
    "Copy and paste the contents of the cell below into the following cell where the solution should be. Fill in the `....` blanks below so that it executes and returns the output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2691f370f4b4058d046810f8b60b25f7",
     "grade": false,
     "grade_id": "cell-02e169611793d840",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=Pipeline(steps=[('columntransformer',\n",
       "                                              ColumnTransformer(transformers=[('drop',\n",
       "                                                                               'drop',\n",
       "                                                                               ['CustomerId']),\n",
       "                                                                              ('standardscaler',\n",
       "                                                                               StandardScaler(),\n",
       "                                                                               ['CreditScore',\n",
       "                                                                                'Age',\n",
       "                                                                                'Tenure',\n",
       "                                                                                'Balance',\n",
       "                                                                                'NumOfProducts',\n",
       "                                                                                'HasCrCard',\n",
       "                                                                                'IsActiveMember',\n",
       "                                                                                'EstimatedSalary']),\n",
       "                                                                              ('onehotencoder-1',\n",
       "                                                                               OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                                               ['Geography']),\n",
       "                                                                              ('o...\n",
       "                                              RandomForestClassifier(class_weight='balanced',\n",
       "                                                                     random_state=123))]),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'randomforestclassifier__max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fe95e276a00>,\n",
       "                                        'randomforestclassifier__n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fe95e0b2ca0>},\n",
       "                   random_state=123, scoring='f1', verbose=1)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "from scipy.stats import randint\n",
    "\n",
    "rf_pipeline = make_pipeline(\n",
    "    preprocessor, RandomForestClassifier(class_weight='balanced', random_state=123)\n",
    ")\n",
    "\n",
    "param_dist = {\n",
    "    \"randomforestclassifier__n_estimators\": scipy.stats.randint(low=10, high=300),\n",
    "    \"randomforestclassifier__max_depth\": scipy.stats.randint(low=2, high=20),\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    rf_pipeline,\n",
    "    param_dist,\n",
    "    n_iter=50,\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    scoring=\"f1\",\n",
    "    random_state=123,\n",
    ")\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2fcb352063b684bc4bbf4808ab24923c",
     "grade": true,
     "grade_id": "cell-329ba0ee56f73721",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2_11(rf_pipeline, random_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.12** <br> {points: 3}\n",
    "\n",
    "What are the best hyperparameter value for `n_estimators` and `max_depth`. Save it in an object named `optimal_parameters` (The auto-grader is expecting a dictionary object). \n",
    "\n",
    "What was the corresponding validation score? Save this in an object named `optimal_score`. \n",
    "\n",
    "*Hint: `.best_params_`  and `.best_score_` are helpful here.* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bc6c6575c2fc2f9b1689150b0ec3740a",
     "grade": false,
     "grade_id": "cell-e5054e9f65a2ecdc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "optimal_parameters = random_search.best_params_\n",
    "optimal_score = random_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5d4f2e85d105299fdd9f45122c039b41",
     "grade": true,
     "grade_id": "cell-f6d885ec6d0c2d90",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t. test_2_12_1(random_search, optimal_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "12d70590bfd258cf23c9fc2abd48421f",
     "grade": true,
     "grade_id": "cell-1f755ca4548b90ca",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# check that the variable exists\n",
    "assert 'optimal_score' in globals(\n",
    "), \"Please make sure that your solution is named 'optimal_score'\"\n",
    "\n",
    "# This test has been intentionally hidden. It will be up to you to decide if your solution\n",
    "# is sufficiently good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.13** <br> {points: 2} \n",
    "\n",
    "What is the train and test score of the best scoring model? Save the result in objects named `training_score`, and `testing_score` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cd39d4e92a20e66646b0ddc210d40c63",
     "grade": false,
     "grade_id": "cell-f0ab8c39cbe9ed7b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "training_score = random_search.score(X_train, y_train)\n",
    "testing_score = random_search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8c5a5380d2510a56431c43e886784c89",
     "grade": true,
     "grade_id": "cell-b8e8776e62548a4e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2_13_1(random_search, training_score, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bd8d66705c6ca034c8a1edacf2411d9d",
     "grade": true,
     "grade_id": "cell-61c66a15b802b184",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2_13_2(random_search, testing_score, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.14** <br> {points: 0} \n",
    "\n",
    "Import the appropriate libraries to plot a confusion matrix and print a classification report. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "509809b5c20010d132e2e040d1da4301",
     "grade": false,
     "grade_id": "cell-1329e2207ccdb878",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import  plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dc8ba5f4ad79ed0617fb09b6fbd31be1",
     "grade": true,
     "grade_id": "cell-519ec2aa08990341",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2_14()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.15** <br> {points: 1} \n",
    "\n",
    "\n",
    "Plot a confusion matrix on the test set using the object `random_search` as your estimator and \"normalize\" all your results (see the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html) for more help here).\n",
    "\n",
    "Name the plot `cm_plot`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "480e44315ece9604fa6621ffc40c4328",
     "grade": false,
     "grade_id": "cell-d4ee02e8d0ad2f1f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_plot = plot_confusion_matrix(random_search, X_test, y_test, normalize = 'true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7e85bf1634b99ccb557f223da6ba10cf",
     "grade": true,
     "grade_id": "cell-e926b5a0a1f975c5",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2_15(cm_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.16** <br> {points: 3} \n",
    "\n",
    "Below print a classification report on the `X_test` predictions of `random_search`'s best model. Use this information to answer the questions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.88      0.90      2395\n",
      "    positive       0.59      0.70      0.64       605\n",
      "\n",
      "    accuracy                           0.84      3000\n",
      "   macro avg       0.76      0.79      0.77      3000\n",
      "weighted avg       0.86      0.84      0.85      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, random_search.predict(X_test), target_names=[\"negative\", \"positive\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "A) What is the recall considering that `Exited`(=1) is our \"positive\" class? Save the result to two decimal places in an object named `answer2_16a`. \n",
    "\n",
    "B) What is the precision weighted average? Save the result to two decimal places in an object named `answer2_16b`. \n",
    "\n",
    "C) How many customers exited in this test set? Save the result as an integer in an object named `answer2_16c`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bd6111addf2a810a4a507c9a53c947f3",
     "grade": false,
     "grade_id": "cell-2a0327eb7dbf23a9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer2_16a = 0.70\n",
    "answer2_16b = 0.86\n",
    "answer2_16c = 605"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "302ef6c3fc4b82d6f5181781ce1b5da8",
     "grade": true,
     "grade_id": "cell-b4b39de2552f60bc",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2_16_1(answer2_16a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b52becccfbd8d1295c376954dbeb3928",
     "grade": true,
     "grade_id": "cell-c4325891305a9cae",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2_16_2(answer2_16b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e8062b3be0407e75ee0d135a3599d875",
     "grade": true,
     "grade_id": "cell-13dafcb469b21ef5",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2_16_3(answer2_16c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.17** <br> {points: 1} \n",
    "\n",
    "What's happened to our model since we have tuned our hyperparameters?\n",
    "\n",
    "A) We have sacrificed some of our precision score for a better recall score.\n",
    "\n",
    "B) Our accuracy has decreased.\n",
    "\n",
    "C) We have likely increased the number of falsely identified exited customers.\n",
    "\n",
    "D) All of the above.\n",
    "\n",
    "*Answer in the cell below using the uppercase letter associated with your answer. Place your answer between `\"\"`, assign the correct answer to an object called `answer2_17`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ace948d39a7b28eb7e874780ca05db55",
     "grade": false,
     "grade_id": "cell-edf2e1be7eceed82",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "answer2_17 = 'D'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e75cf6d8e572e548aa27b98b0a251896",
     "grade": true,
     "grade_id": "cell-f0db9a56f75d6b9a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_2_17(answer2_17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Regression Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, we will bring back the [Taiwan real estate valuation dataset](https://archive.ics.uci.edu/ml/datasets/Real+estate+valuation+data+set) that we saw in assignment 1. \n",
    "\n",
    "We are doing the first part for you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>house_age</th>\n",
       "      <th>distance_station</th>\n",
       "      <th>num_stores</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>13.2</td>\n",
       "      <td>150.9347</td>\n",
       "      <td>7</td>\n",
       "      <td>24.96725</td>\n",
       "      <td>121.54252</td>\n",
       "      <td>48.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>10.3</td>\n",
       "      <td>3079.8900</td>\n",
       "      <td>0</td>\n",
       "      <td>24.95460</td>\n",
       "      <td>121.56627</td>\n",
       "      <td>24.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>34.7</td>\n",
       "      <td>482.7581</td>\n",
       "      <td>5</td>\n",
       "      <td>24.97433</td>\n",
       "      <td>121.53863</td>\n",
       "      <td>41.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>16.4</td>\n",
       "      <td>1643.4990</td>\n",
       "      <td>2</td>\n",
       "      <td>24.95394</td>\n",
       "      <td>121.55174</td>\n",
       "      <td>24.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>15.6</td>\n",
       "      <td>289.3248</td>\n",
       "      <td>5</td>\n",
       "      <td>24.98203</td>\n",
       "      <td>121.54348</td>\n",
       "      <td>46.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     house_age  distance_station  num_stores  latitude  longitude  price\n",
       "82        13.2          150.9347           7  24.96725  121.54252   48.1\n",
       "307       10.3         3079.8900           0  24.95460  121.56627   24.7\n",
       "267       34.7          482.7581           5  24.97433  121.53863   41.1\n",
       "310       16.4         1643.4990           2  24.95394  121.55174   24.7\n",
       "203       15.6          289.3248           5  24.98203  121.54348   46.1"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df = pd.read_csv('data/real_estate.csv')\n",
    "train_df, test_df = train_test_split(housing_df, test_size=0.2, random_state=123)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop(columns=['price'])\n",
    "y_train = train_df['price']\n",
    "\n",
    "X_test = test_df.drop(columns=['price'])\n",
    "y_test = test_df['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.1** <br> {points: 1}  \n",
    "\n",
    "Since we have seen this dataset already, we know there are only numeric features and no missing values so we can skip quite a few steps here. \n",
    "\n",
    "Make a single pipeline using `make_pipeline` named `reg_pipe` that first uses `StandardScaler()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e9af4530f8eb18b97eb08ec40d3a2bf9",
     "grade": false,
     "grade_id": "cell-69d4e91a504c1837",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "reg_pipe = make_pipeline(StandardScaler(), SVR())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4612d4f03ef95081fd478e668f33a43c",
     "grade": true,
     "grade_id": "cell-d8d5d76226e3a145",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_3_1(reg_pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.2** <br> {points: 1}  \n",
    "\n",
    "Given the MAPE function we have given below, create a scorer function that we can pass into cross-validation. (look [here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html?highlight=make_scorer#sklearn.metrics.make_scorer) for help). \n",
    "\n",
    "Save it in an object named `mape_scorer`. Remember that MAPE is an error measure so we must use `greater_is_better=False` as an argument. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fde6497e6e3e0a29d03f941ef910781f",
     "grade": false,
     "grade_id": "cell-bfca9f71be42499d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def mape(true, pred):\n",
    "    return 100.0 * np.mean(np.abs((pred - true) / true))\n",
    "mape_scorer = make_scorer(mape, greater_is_better = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f81e0134de01413a96b383f142c636e8",
     "grade": true,
     "grade_id": "cell-8a3cf905241ca8b0",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_3_2(mape_scorer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.3** <br> {points: 1}  \n",
    "\n",
    "Make a dictionary named `scoring_dict` consisting the following metrics: \n",
    "\n",
    "- `neg_mean_squared_error`\n",
    "- `neg_root_mean_square_error`\n",
    "- `neg_mean_absolute_error`\n",
    "- `r2`\n",
    "- `mape_scorer`\n",
    "\n",
    "The key-value pairs in this dictionary should be identical. (Aka the item to the left of the colon is the same as the right side of the colon - we have started it for you just in case.)\n",
    "\n",
    "Remember that `mape_scorer` is a variable and should **NOT** be called as a string. (Although we need to name it as a string value for the dictionary's key; See slide 6 of exercise 21 for help.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3c3641b48327a66e14164e8ad1a67466",
     "grade": false,
     "grade_id": "cell-b824fb2b08c194e2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "scoring_dict = {\"neg_mean_squared_error\": \"neg_mean_squared_error\",\n",
    "                \"neg_root_mean_square_error\" : \"neg_root_mean_squared_error\",\n",
    "                \"neg_mean_absolute_error\" : \"neg_mean_absolute_error\",\n",
    "                \"r2\" : \"r2\",\n",
    "                \"mape_scorer\" : mape_scorer\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "01f9e8795770ec95137b9ccb85f8cd6c",
     "grade": true,
     "grade_id": "cell-2262d2645f47df97",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_3_3(scoring_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.4** <br> {points: 1}  \n",
    "\n",
    "Carry out cross-validation on `reg_pipe` and the training set using the `cross_validate` function.\n",
    "\n",
    "Make sure to set `return_train_score=True` and assign our `scoring_dict` to the `scoring` argument.\n",
    "\n",
    "\n",
    "Save the results of the cross-validation in a dataframe named `regression_scores`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2527d12fdfdf960f1d3acab42c5ddb5f",
     "grade": false,
     "grade_id": "cell-457e7772f822ea07",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "regression_scores = pd.DataFrame(cross_validate(reg_pipe, X_train, y_train, return_train_score = True, scoring = scoring_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dd455c6298edcf13a392ef3405e5012a",
     "grade": true,
     "grade_id": "cell-db06848393467bff",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_3_4(regression_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.5** <br> {points: 1} \n",
    "\n",
    "What is the mean of each column in `regression_scores`?\n",
    "\n",
    "\n",
    "Save your result in an object named `regression_mean`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4d3a064443139b53c79cf608f0aab5f0",
     "grade": false,
     "grade_id": "cell-cfb55ddae37d8d25",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "regression_mean = regression_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "25375c0d00b9b4c14317da96188d4586",
     "grade": true,
     "grade_id": "cell-4993cba10fcfe8c5",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.test_3_5(regression_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.6** <br> {points: 2} \n",
    "\n",
    "What is the model's mean validation MAPE score? \n",
    "\n",
    "Save your answer to 2 decimal places in an object named `mean_reg_mape`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c594f14a6dc459dbbc2fd63f43fb5970",
     "grade": false,
     "grade_id": "cell-9cfd9da29de1973e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "mean_reg_mape = -16.77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "29975a2ec1f868886a0f90d1f13875f9",
     "grade": true,
     "grade_id": "cell-763f0a302ba20680",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# check that the variable exists\n",
    "assert 'mean_reg_mape' in globals(\n",
    "), \"Please make sure that your solution is named 'mean_reg_mape'\"\n",
    "\n",
    "# This test has been intentionally hidden. It will be up to you to decide if your solution\n",
    "# is sufficiently good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attributions\n",
    "- The Bank Customer Churn DataSet - [Kaggle](https://www.kaggle.com/shubh0799/churn-modelling)\n",
    "\n",
    "- Real Estate Dataset - [The UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Real+estate+valuation+data+set)\n",
    "\n",
    "*Yeh, I. C., & Hsu, T. K. (2018). Building real estate valuation models with comparative approach through case-based reasoning. Applied Soft Computing, 65, 260-271.*\n",
    "\n",
    "\n",
    "- MDS DSCI 573 - Feature & Model Selection  - [MDS's GitHub website](https://github.com/UBC-MDS/DSCI_573_feat-model-select) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before Submitting \n",
    "\n",
    "Before submitting your assignment please do the following:\n",
    "\n",
    "- Read through your solutions\n",
    "- **Restart your kernel and clear output and rerun your cells from top to bottom** \n",
    "- Makes sure that none of your code is broken \n",
    "- Verify that the tests from the questions you answered have obtained the output \"Success\"\n",
    "\n",
    "This is a simple way to make sure that you are submitting all the variables needed to mark the assignment. This method should help avoid losing marks due to changes in your environment.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
